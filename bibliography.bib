%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/

%% Created for Guha, Rajarshi (NIH/NCATS) [C] at 2017-09-04 00:11:15 -0400 

@Article{PPilot,
   Author="Hassan, M.  and Brown, R. D.  and Varma-O'brien, S.  and Rogers, D. ",
   Title="{{C}heminformatics analysis and learning in a data pipelining environment}",
   Journal="Mol. Divers.",
   Year="2006",
   Volume="10",
   Number="3",
   Pages="283--299",
   Month="Aug"
}


@MISC{RDKit,
  title = {{RDK}it: Open-source cheminformatics},
  howpublished = {\url{http://www.rdkit.org}},
  note = {[Online; accessed 11-April-2013]},
  key = {RDKit, online}
}

@Article{JChem,
   Author="Csizmadia, F. ",
   Title="{{J}{C}hem: {J}ava applets and modules supporting chemical database handling from web browsers}",
   Journal="J Chem Inf Comput Sci",
   Year="2000",
   Volume="40",
   Number="2",
   Pages="323--324",
   Month="Mar"
}

@Article{ELT,
   Author="Clark, M. A.  and Acharya, R. A.  and Arico-Muendel, C. C.  and Belyanskaya, S. L.  and Benjamin, D. R.  and Carlson, N. R.  and Centrella, P. A.  and Chiu, C. H.  and Creaser, S. P.  and Cuozzo, J. W.  and Davie, C. P.  and Ding, Y.  and Franklin, G. J.  and Franzen, K. D.  and Gefter, M. L.  and Hale, S. P.  and Hansen, N. J.  and Israel, D. I.  and Jiang, J.  and Kavarana, M. J.  and Kelley, M. S.  and Kollmann, C. S.  and Li, F.  and Lind, K.  and Mataruse, S.  and Medeiros, P. F.  and Messer, J. A.  and Myers, P.  and O'Keefe, H.  and Oliff, M. C.  and Rise, C. E.  and Satz, A. L.  and Skinner, S. R.  and Svendsen, J. L.  and Tang, L.  and van Vloten, K.  and Wagner, R. W.  and Yao, G.  and Zhao, B.  and Morgan, B. A. ",
   Title="{{D}esign, synthesis and selection of {D}{N}{A}-encoded small-molecule libraries}",
   Journal="Nat. Chem. Biol.",
   Year="2009",
   Volume="5",
   Number="9",
   Pages="647--654",
   Month="Sep"
}

%% Saved with string encoding Unicode (UTF-8) 
@Unpublished{Bandyopadhyay2012ACS,
title={{D}ynamic {SA}/reports: Analyzing current project and {HTS} data by interactive selection of frequently-occurring scaffolds},
abstract = {Diverse compound sets, such as high-throughput screening (HTS) hit sets containing an unknown number of chemotypes, have traditionally been analyzed by clustering, nearest neighbors, or other scaffold-agnostic methods rather than by rigorous R-group analysis. Here we describe how MOE SA/Report has been applied to analyze 2-4k compound subsets of the GSK screening collection having measured activity (percent inhibition or pIC50) against one or more screened targets. Since the default scaffold auto-detection within SA/Report is tuned for datasets with many exemplars of a few scaffolds as opposed to more diverse HTS hit sets, we use an interactive scaffold selection approach. The user is allowed to pick a scaffold from the highest ranked (most frequent and largest) fragments found in the data, and frequent fragments are then found in the remaining unmapped compounds. Both these steps continue iteratively until scaffold selection is complete. We also describe how MOE SA/Report has been integrated into project data delivery mechanisms at GSK, with reports being run automatically for several projects on their current set of compounds via custom KNIME workflows.},
author = {Deepak Bandyopadhyay},
affiliation = {GlaxoSmithKline},
details = {http://acselb-529643017.us-west-2.elb.amazonaws.com/chem/244nm/program/view.php},
location = {Philadelphia, Pennsylvania, USA},
note = {244th American Chemistry Society National Meeting, Philadelphia, PA, August 19-23, 2012},
year = {2012}
}

@Unpublished{Chakravorty2013IFI,
title={On the compound annotation and cleaning the {GSK} screening collection initiative: The utility of an {I}nhibition {F}requency {I}ndex ({IFI})},
abstract = {High throughput screening (HTS) constitutes a critical tool for the identification of lead molecules from primary screening assays for novel targets. GlaxoSmithKline (GSK) has continuously invested in the development and curation of its HTS collection to maximize the number of quality starting points for drug discovery and reduce the number of false positives from primary screens. An Inhibition Frequency Index (IFI) has been defined as a measure of promiscuity of individual compounds in HTS primary assays based upon activities tabulated over time in GSK's exhaustive screening assay tables. In this talk, we will present our analysis of the IFI profile across the GSK HTS collection. We will characterize the IFI profile with respect to desired physical properties, will discuss obvious substructures that may be less attractive as starting points, and will describe new classes of nuisance compounds revealed by our IFI analysis. In addition, we will examine the IFI of promiscuity filters described in the literature. There are many reasons why any particular molecule might display promiscuity: physical properties of the compound, properties of the target or target class, details of the assay and the assay technology and methodology. All of these factors must be considered when deciding whether to remove or retain a compound in a curated HTS collection.},
author = {Subhas J Chakravorty and James A Chan and Juan Luengo and Nicole M Greenwood and Ioana Popa-Burke and Ricardo Macarron},
affiliation = {GlaxoSmithKline},
details = {http://acselb-529643017.us-west-2.elb.amazonaws.com/chem/245nm/program/view.php},
location = {New Orleans, Louisiana, USA},
note = {245th American Chemistry Society National Meeting, New Orleans, LA, April 7-11, 2013},
year = {2013}
}

@Unpublished{Richmond2013Galois,
title={Hierarchical Fuzzy Clustering with a {G}alois Lattice},
abstract = {A Galois lattice is a formal ontology derived from a collection of objects and their attributes. A node of the lattice corresponds to a subset of the objects sharing the same subset of the attributes and two nodes are connected if the object set of one node is a subset of the object set of the other node. This approach to structuring data has been widely used in a number of information related fields such as data mining, text mining, machine learning and knowledge management and more recently in the area of market basket analysis, where retailers seek to understand the purchasing behaviour of their customers to aid with store design and sales promotions amongst others. As an example, given a data set of consumers (object) and their transactions (attributes), a retailer can learn, via the lattice, that shampoo and conditioner are frequently bought together, so placing both products on promotion at the same time would not necessarily have a positive impact on profit.

The use of Galois lattices also extends to bioinformatics but the use of these lattices in the field of chemoinformatics has been limited to the identification of privileged fragments. Here we describe an algorithm where the lattice itself, as opposed to the association rules it generates, is exploited to provide a hierarchical, fuzzy clustering that has a number of applications in chemoinformatics.

In our scenario, the objects of our data set correspond to molecules and the attributes correspond to the set of all possible fragments of these molecules. A node in the Galois lattice of this data then corresponds to a set of molecules sharing a set of common fragments. The bottom of the lattice contains single molecules and all their possible fragments and each node along an upward path contains a bigger superset of molecules, clustered together on smaller subsets of common fragments.

In general, Galois lattices can become large enough that the problem of mining the data becomes one of mining the lattice. To reduce the size and complexity of the lattice, we can stipulate a lower bound on the generated fragment atom count, thus reducing the number of lattice nodes and, at the same time, providing more chemically meaningful clusters. A further reduction in nodes can also be achieved by applying a minimum bound of the number of shared attributes.

There are two applications we focus on, one is the generation of a hierarchical clustering that can be visually inspected and interrogated within Cytoscape, the other is the automated R-group analysis of a SAR data set. We compare the application of Galois lattices to these problems with existing methodologies. 

Typically, the computational chemist will manually fragment a SAR data set using a series of substructures searches. This process can be time consuming due to the number of repeats often required to achieve the desired fragmentation. This lattice based approach provides an automated fragmentation and hierarchy, and by incorporating experimental activity data, a lattice node can be assigned an average activity. Thus when walking up the lattice, the addition of a molecule and the subsequent loss of fragments can modify the average activity of the lattice node. These changes are easily identified and can provide valuable insight to the medicinal chemist.},
author = {Nicola Richmond},
affiliation = {GlaxoSmithKline},
details = {http://cisrg.shef.ac.uk/shef2013/showabstract.php?id=55},
location = {Sheffield, UK},
note = {6th Joint Sheffield Conference on Chemoinformatics, Sheffield, UK, July 22-24, 2013},
year = {2013}
}



@article{Posner2009,
abstract = {The postprocessing of high-throughput screening (HTS) results is complicated by the occurrence of false positives (inactive compounds misidentified as active by the primary screen) and false negatives (active compounds misidentified as inactive by the primary screen). An activity cutoff is frequently used to select "active" compounds from HTS data; however, this approach is insensitive to both false positives and false negatives. An alternative method that can minimize the occurrence of these artifacts will increase the efficiency of hit selection and therefore lead discovery. In this work, rather than merely using the activity of a given compound, we look at the presence and absence of activity among all compounds in its "chemical space neighborhood" to give a degree of confidence in its activity. We demonstrate that this local hit rate (LHR) analysis method outperforms hit selection based on ranking by primary screen activity values across ten diverse high throughput screens, spanning both cell-based and biochemical assay formats of varying biology and robustness. On average, the local hit rate analysis method was approximately 2.3-fold and approximately 1.3-fold more effective in identifying active compounds and active chemical series, respectively, than selection based on primary activity alone. Moreover, when applied to finding false negatives, this method was 2.3-fold better than ranking by primary activity alone. In most cases, novel hit series were identified that would have otherwise been missed. Additional uses of and observations regarding this HTS analysis approach are also discussed.},
author = {Posner, Bruce A. and Xi, Hualin and Mills, James E J},
doi = {10.1021/ci900113d},
isbn = {1549-9596},
issn = {15499596},
journal = {Journal of Chemical Information and Modeling},
number = {10},
pages = {2202--2210},
pmid = {19795815},
title = {{Enhanced HTS hit selection via a local hit rate analysis}},
volume = {49},
year = {2009}
}


@article{Hu:2016aa,
	Abstract = {The scaffold concept is widely applied in medicinal chemistry. Scaffolds are mostly used to represent core structures of bioactive compounds. Although the scaffold concept has limitations and is often viewed differently from a chemical and computational perspective, it has provided a basis for systematic investigations of molecular cores and building blocks, going far beyond the consideration of individual compound series. Over the past 2 decades, alternative scaffold definitions and organization schemes have been introduced and scaffolds have been studied in a variety of ways and increasingly on a large scale. Major applications of the scaffold concept include the generation of molecular hierarchies, structural classification, association of scaffolds with biological activities, and activity prediction. This contribution discusses computational approaches for scaffold generation and analysis, with emphasis on recent developments impacting medicinal chemistry. A variety of scaffold-based studies are discussed, and a perspective on scaffold methods is provided.},
	Author = {Hu, Ye and Stumpfe, Dagmar and Bajorath, J{\"u}rgen},
	Date-Added = {2017-09-04 03:02:59 +0000},
	Date-Modified = {2017-09-04 03:03:08 +0000},
	Doi = {10.1021/acs.jmedchem.5b01746},
	Journal = {J.~Med.~Chem.},
	Journal-Full = {Journal of medicinal chemistry},
	Mesh = {Algorithms; Binding Sites; Chemistry, Pharmaceutical; Drug Discovery; Kinetics; Thermodynamics},
	Month = {May},
	Number = {9},
	Pages = {4062--4076},
	Pmid = {26840095},
	Pst = {ppublish},
	Title = {Computational Exploration of Molecular Scaffolds in Medicinal Chemistry},
	Volume = {59},
	Year = {2016},
	Bdsk-Url-1 = {http://dx.doi.org/10.1021/acs.jmedchem.5b01746}}

@article{Khanna:2011aa,
	Abstract = {BACKGROUND: The recent public availability of the human metabolome and natural product datasets has revitalized "metabolite-likeness" and "natural product-likeness" as a drug design concept to design lead libraries targeting specific pathways. Many reports have analyzed the physicochemical property space of biologically important datasets, with only a few comprehensively characterizing the scaffold diversity in public datasets of biological interest. With large collections of high quality public data currently available, we carried out a comparative analysis of current day leads with other biologically relevant datasets.
RESULTS: In this study, we note a two-fold enrichment of metabolite scaffolds in drug dataset (42%) as compared to currently used lead libraries (23%). We also note that only a small percentage (5%) of natural product scaffolds space is shared by the lead dataset. We have identified specific scaffolds that are present in metabolites and natural products, with close counterparts in the drugs, but are missing in the lead dataset. To determine the distribution of compounds in physicochemical property space we analyzed the molecular polar surface area, the molecular solubility, the number of rings and the number of rotatable bonds in addition to four well-known Lipinski properties. Here, we note that, with only few exceptions, most of the drugs follow Lipinski's rule. The average values of the molecular polar surface area and the molecular solubility in metabolites is the highest while the number of rings is the lowest. In addition, we note that natural products contain the maximum number of rings and the rotatable bonds than any other dataset under consideration.
CONCLUSIONS: Currently used lead libraries make little use of the metabolites and natural products scaffold space. We believe that metabolites and natural products are recognized by at least one protein in the biosphere therefore, sampling the fragment and scaffold space of these compounds, along with the knowledge of distribution in physicochemical property space, can result in better lead libraries. Hence, we recommend the greater use of metabolites and natural products while designing lead libraries. Nevertheless, metabolites have a limited distribution in chemical space that limits the usage of metabolites in library design.},
	Author = {Khanna, Varun and Ranganathan, Shoba},
	Date-Added = {2017-09-04 03:00:32 +0000},
	Date-Modified = {2017-09-04 03:00:42 +0000},
	Doi = {10.1186/1758-2946-3-30},
	Journal = {J.~Cheminf.},
	Journal-Full = {Journal of cheminformatics},
	Month = {Aug},
	Pages = {30},
	Pmc = {PMC3179739},
	Pmid = {21824432},
	Pst = {epublish},
	Title = {Structural diversity of biologically interesting datasets: a scaffold analysis approach},
	Volume = {3},
	Year = {2011},
	Bdsk-Url-1 = {http://dx.doi.org/10.1186/1758-2946-3-30}}

@article{Shanmugasundaram:2005aa,
	Abstract = {This work describes a practical strategy used at Pharmacia for identifying compounds for follow-up screening following an initial HTS campaign against targets where no 3-D structural information is available and preliminary SAR models do not exist. The approach explicitly takes into account different representations of chemistry space and identifies compounds for follow-up screening that are likely to provide the best overall coverage of the chemistry spaces considered. Specifically, the work employs hit-directed nearest-neighbor (HDNN) searching of compound databases based upon a set of "probe compounds" obtained as hits in the preliminary high-throughput screens. Four different molecular representations that generate nearly unique chemistry spaces are used. The representations include 3-D, 2-D, 2-D topological BCUTs (2-DT) and molecular fingerprints derived from substructural fragments. In the case of the BCUT representations the NN searching is distance based, while in the case of molecular fingerprints a similarity-based measure is used. Generally, the results obtained differ significantly among all four methods, that is, the sets of NN compounds have surprisingly little overlap. Moreover, in all of the four chemistry space representations, a minimum of 3- to 4-fold enrichment in actives over random screening is observed even though the actives identified in each of the sets of NNs are in large measure unique. These results suggest that use of multiple searches based upon a variety of molecular representations provides an effective way of identifying more hits in HDNN searches of chemistry spaces than can be realized with single searches.},
	Author = {Shanmugasundaram, Veerabahu and Maggiora, Gerald M and Lajiness, Michael S},
	Date-Added = {2017-09-04 02:54:59 +0000},
	Date-Modified = {2017-09-04 02:55:10 +0000},
	Doi = {10.1021/jm0493515},
	Journal = {J.~Med.~Chem.},
	Journal-Full = {Journal of medicinal chemistry},
	Mesh = {Bacteria; Combinatorial Chemistry Techniques; Databases, Factual; Drug Design; Drug Evaluation, Preclinical; Enzymes; Mathematics; Models, Chemical; Receptors, Cytoplasmic and Nuclear; Software},
	Month = {Jan},
	Number = {1},
	Pages = {240--248},
	Pmid = {15634017},
	Pst = {ppublish},
	Title = {Hit-directed nearest-neighbor searching},
	Volume = {48},
	Year = {2005},
	Bdsk-Url-1 = {http://dx.doi.org/10.1021/jm0493515}}

@article{Mulrooney:2013aa,
	Abstract = {Integration of flexible data-analysis tools with cheminformatics methods is a prerequisite for successful identification and validation of "hits" in high-throughput screening (HTS) campaigns. We have designed, developed, and implemented a suite of robust yet flexible cheminformatics tools to support HTS activities at the Broad Institute, three of which are described herein. The "hit-calling" tool allows a researcher to set a hit threshold that can be varied during downstream analysis. The results from the hit-calling exercise are reported to a database for record keeping and further data analysis. The "cherry-picking" tool enables creation of an optimized list of hits for confirmatory and follow-up assays from an HTS hit list. This tool allows filtering by computed chemical property and by substructure. In addition, similarity searches can be performed on hits of interest and sets of related compounds can be selected. The third tool, an "S/SAR viewer," has been designed specifically for the Broad Institute's diversity-oriented synthesis (DOS) collection. The compounds in this collection are rich in chiral centers and the full complement of all possible stereoisomers of a given compound are present in the collection. The S/SAR viewer allows rapid identification of both structure/activity relationships and stereo-structure/activity relationships present in HTS data from the DOS collection. Together, these tools enable the prioritization and analysis of hits from diverse compound collections, and enable informed decisions for follow-up biology and chemistry efforts.},
	Author = {Mulrooney, Carol A and Lahr, David L and Quintin, Michael J and Youngsaye, Willmen and Moccia, Dennis and Asiedu, Jacob K and Mulligan, Evan L and Akella, Lakshmi B and Marcaurelle, Lisa A and Montgomery, Philip and Bittker, Joshua A and Clemons, Paul A and Brudz, Stephen and Dandapani, Sivaraman and Duvall, Jeremy R and Tolliday, Nicola J and De Souza, Andrea},
	Date-Added = {2017-09-04 01:33:49 +0000},
	Date-Modified = {2017-09-04 01:34:07 +0000},
	Doi = {10.1007/s10822-013-9641-y},
	Journal = {J.~Comp.~Aided Mol.~Des.},
	Journal-Full = {Journal of computer-aided molecular design},
	Mesh = {Algorithms; Combinatorial Chemistry Techniques; Databases, Factual; Drug Design; High-Throughput Screening Assays; Humans; Structure-Activity Relationship},
	Month = {May},
	Number = {5},
	Pages = {455--468},
	Pmc = {PMC5554947},
	Pmid = {23585218},
	Pst = {ppublish},
	Title = {An informatic pipeline for managing high-throughput screening experiments and analyzing data from stereochemically diverse libraries},
	Volume = {27},
	Year = {2013},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/s10822-013-9641-y}}

@article{Torres2009,
	Author = {Guadalupe J. Torres and Ram B. Basnet and Andrew H. Sung and Srinivas Mukkamala and Bernardete M},
	Journal = {Int J Electr Comput Syst Eng},
	Number = {3},
	Pages = {164--170},
	Title = {A Similarity Measure for Clustering and its Applications},
	Url = {https://www.cs.nmt.edu/~rbasnet/research/ClusteringSimilarityAndItsApplications.pdf},
	Volume = {3},
	Year = {2009},
	Bdsk-Url-1 = {https://www.cs.nmt.edu/~rbasnet/research/ClusteringSimilarityAndItsApplications.pdf}}

@article{Jain2010,
	Abstract = {Organizing data into sensible groupings is one of the most fundamental modes of understanding and learning. As an example, a common scheme of scientific classification puts organisms into a system of ranked taxa: domain, kingdom, phylum, class, etc. Cluster analysis is the formal study of methods and algorithms for grouping, or clustering, objects according to measured or perceived intrinsic characteristics or similarity. Cluster analysis does not use category labels that tag objects with prior identifiers, i.e., class labels. The absence of category information distinguishes data clustering (unsupervised learning) from classification or discriminant analysis (supervised learning). The aim of clustering is to find structure in data and is therefore exploratory in nature. Clustering has a long and rich history in a variety of scientific fields. One of the most popular and simple clustering algorithms, K-means, was first published in 1955. In spite of the fact that K-means was proposed over 50 years ago and thousands of clustering algorithms have been published since then, K-means is still widely used. This speaks to the difficulty in designing a general purpose clustering algorithm and the ill-posed problem of clustering. We provide a brief overview of clustering, summarize well known clustering methods, discuss the major challenges and key issues in designing clustering algorithms, and point out some of the emerging and useful research directions, including semi-supervised clustering, ensemble clustering, simultaneous feature selection during data clustering, and large scale data clustering. ?? 2009 Elsevier B.V. All rights reserved.},
	Archiveprefix = {arXiv},
	Arxivid = {arXiv:cond-mat/0402594v3},
	Author = {Jain, Anil K.},
	Doi = {10.1016/j.patrec.2009.09.011},
	Eprint = {0402594v3},
	Isbn = {9781424417360},
	Issn = {01678655},
	Journal = {Pattern Recognition Letters},
	Keywords = {Data clustering,Historical developments,King-Sun Fu prize,Perspectives on clustering,User's dilemma},
	Number = {8},
	Pages = {651--666},
	Primaryclass = {arXiv:cond-mat},
	Title = {{Data clustering: 50 years beyond K-means}},
	Url = {http://dx.doi.org/10.1016/j.patrec.2009.09.011},
	Volume = {31},
	Year = {2010},
	Bdsk-Url-1 = {http://dx.doi.org/10.1016/j.patrec.2009.09.011}}

@article{Downs2003,
	Abstract = {Summary Chapter 1 describes clustering methods and reviews their uses in computational chemistry. The chapter covers: Clustering Algorithms Hierarchical Methods Nonhierarchical Methods Progress in Methodology Algorithm Developments Comparative Studies on Chemical Data Sets How Many Clusters? Chemical Applications},
	Author = {Downs, Gm and Barnard, Jm},
	Doi = {10.1002/0471433519.ch1},
	Isbn = {9780471433514},
	Issn = {1069-3599},
	Journal = {Reviews in computational chemistry},
	Pages = {1--40},
	Title = {{Clustering methods and their uses in computational chemistry}},
	Url = {http://books.google.com/books?hl=en{\&}lr={\&}id=IqWXSLz6QE8C{\&}oi=fnd{\&}pg=PA1{\&}dq=Clustering+Methods+and+Their+Uses+in+Computational+Chemistry{\&}ots=4ZhelOH4M2{\&}sig=vFXdRM9OhaAOGXNvi0jliGd-fdw},
	Volume = {18},
	Year = {2003},
	Bdsk-Url-1 = {http://books.google.com/books?hl=en%7B%5C&%7Dlr=%7B%5C&%7Did=IqWXSLz6QE8C%7B%5C&%7Doi=fnd%7B%5C&%7Dpg=PA1%7B%5C&%7Ddq=Clustering+Methods+and+Their+Uses+in+Computational+Chemistry%7B%5C&%7Dots=4ZhelOH4M2%7B%5C&%7Dsig=vFXdRM9OhaAOGXNvi0jliGd-fdw},
	Bdsk-Url-2 = {http://dx.doi.org/10.1002/0471433519.ch1}}

@article{Hill2010,
	Abstract = {Suboptimal physical properties have been identified as a particular shortcoming of compounds in contemporary drug discovery, contributing to high attrition levels. An analysis of the relationship between hydrophobicity (calculated and measured) and ???100k measured kinetic solubility values has been undertaken. In line with the General Solubility Equation, estimates of hydrophobicity, particularly ACD clogDpH7.4, give a useful indication of the likely solubility classification of particular molecules. Taking ACD clogDpH7.4 values together with the number of aromatic rings in a given molecule provides enhanced prediction. The 'Solubility Forecast Index' (SFI=clogDpH7.4+{\#}Ar) is proposed as a simple, yet effective, guide to predicting solubility. Moreover, analysis of measured distribution/partition coefficient values highlighted statistically significant shortcomings in the applicability of octanol/water as a model system for hydrophobicity determination with poorly soluble compounds. ?? 2010 Elsevier Ltd.},
	Author = {Hill, Alan P. and Young, Robert J.},
	Doi = {10.1016/j.drudis.2010.05.016},
	Isbn = {1878-5832 (Electronic)$\backslash$r1359-6446 (Linking)},
	Issn = {13596446},
	Journal = {Drug Discovery Today},
	Number = {15-16},
	Pages = {648--655},
	Pmid = {20570751},
	Title = {{Getting physical in drug discovery: A contemporary perspective on solubility and hydrophobicity}},
	Url = {http://dx.doi.org/10.1016/j.drudis.2010.05.016},
	Volume = {15},
	Year = {2010},
	Bdsk-Url-1 = {http://dx.doi.org/10.1016/j.drudis.2010.05.016}}

@article{Young2011,
	Abstract = {Here, we review the performance of chromatographic hydrophobicity measurements in a data set of 100 000 GlaxoSmithKline compounds, demonstrating the advantages of the method over octanol-water partitioning and highlighting new insights for drug discovery. The value of chromatographic measurements, versus other hydrophobicity estimates, was supported by improved relationships with solubility, permeation, cytochrome P450s, intrinsic clearance, hERG binding and promiscuity. We also observed marked differentiation of the relative influence of intrinsic and effective hydrophobicity. The summing of hydrophobicity values plus aromatic ring count [log D pH7.4 (or log P) + {\#}Ar], indicated a wide relevance for simplistic 'property forecast indices' in developability assays, clearly enhanced by chromatographic values; therefore establishing new foundations for enriching property-based drug design. ?? 2011 Elsevier Ltd.},
	Author = {Young, Robert J. and Green, Darren V S and Luscombe, Christopher N. and Hill, Alan P.},
	Doi = {10.1016/j.drudis.2011.06.001},
	Isbn = {1878-5832 (Electronic) 1359-6446 (Linking)},
	Issn = {13596446},
	Journal = {Drug Discovery Today},
	Number = {17-18},
	Pages = {822--830},
	Pmid = {21704184},
	Title = {{Getting physical in drug discovery II: The impact of chromatographic hydrophobicity measurements and aromaticity}},
	Url = {http://dx.doi.org/10.1016/j.drudis.2011.06.001},
	Volume = {16},
	Year = {2011},
	Bdsk-Url-1 = {http://dx.doi.org/10.1016/j.drudis.2011.06.001}}

@article{Ertl:2014eu,
	Abstract = {Scaffold Keys-scaffold descriptors based on simple topological parameters such as number of ring and chain atoms, number and type of heteroatoms, and other simple structural features-are presented. Scaffold Keys enable intuitive ordering of scaffolds from small and simple to large and complex, ordering that is consistent with the way medicinal chemists themselves classify scaffolds. Scaffold Keys may be also used as descriptors for scaffold similarity searches, providing results compatible with expectations of chemists and well-suited for use in scaffold bioisosteric replacement and scaffold hopping. Scaffold Keys also support visualization of large chemical data sets. Scaffold Keys descriptors are easy to understand by chemists as well as easy to implement.},
	Author = {Ertl, Peter},
	Date-Added = {2016-01-05 17:09:35 +0000},
	Date-Modified = {2016-01-05 17:09:56 +0000},
	Doi = {10.1021/ci5001983},
	Journal = {J.~Chem.~Inf.~Model.},
	Journal-Full = {Journal of chemical information and modeling},
	Mesh = {Databases, Chemical; Drug Design; Pharmaceutical Preparations; Search Engine; Software},
	Month = {Jun},
	Number = {6},
	Pages = {1617--1622},
	Pmid = {24846291},
	Pst = {ppublish},
	Title = {Intuitive ordering of scaffolds and scaffold similarity searching using scaffold keys},
	Volume = {54},
	Year = {2014},
	Bdsk-Url-1 = {http://dx.doi.org/10.1021/ci5001983}}

@article{Khanna:2011qf,
	Abstract = {BACKGROUND: The recent public availability of the human metabolome and natural product datasets has revitalized "metabolite-likeness" and "natural product-likeness" as a drug design concept to design lead libraries targeting specific pathways. Many reports have analyzed the physicochemical property space of biologically important datasets, with only a few comprehensively characterizing the scaffold diversity in public datasets of biological interest. With large collections of high quality public data currently available, we carried out a comparative analysis of current day leads with other biologically relevant datasets.
RESULTS: In this study, we note a two-fold enrichment of metabolite scaffolds in drug dataset (42\%) as compared to currently used lead libraries (23\%). We also note that only a small percentage (5\%) of natural product scaffolds space is shared by the lead dataset. We have identified specific scaffolds that are present in metabolites and natural products, with close counterparts in the drugs, but are missing in the lead dataset. To determine the distribution of compounds in physicochemical property space we analyzed the molecular polar surface area, the molecular solubility, the number of rings and the number of rotatable bonds in addition to four well-known Lipinski properties. Here, we note that, with only few exceptions, most of the drugs follow Lipinski's rule. The average values of the molecular polar surface area and the molecular solubility in metabolites is the highest while the number of rings is the lowest. In addition, we note that natural products contain the maximum number of rings and the rotatable bonds than any other dataset under consideration.
CONCLUSIONS: Currently used lead libraries make little use of the metabolites and natural products scaffold space. We believe that metabolites and natural products are recognized by at least one protein in the biosphere therefore, sampling the fragment and scaffold space of these compounds, along with the knowledge of distribution in physicochemical property space, can result in better lead libraries. Hence, we recommend the greater use of metabolites and natural products while designing lead libraries. Nevertheless, metabolites have a limited distribution in chemical space that limits the usage of metabolites in library design.},
	Author = {Khanna, Varun and Ranganathan, Shoba},
	Date-Added = {2016-01-05 15:02:44 +0000},
	Date-Modified = {2016-01-05 15:02:56 +0000},
	Doi = {10.1186/1758-2946-3-30},
	Journal = {J.~Cheminf.},
	Journal-Full = {Journal of cheminformatics},
	Pages = {30},
	Pmc = {PMC3179739},
	Pmid = {21824432},
	Pst = {epublish},
	Title = {Structural diversity of biologically interesting datasets: {A} scaffold analysis approach},
	Volume = {3},
	Year = {2011},
	Bdsk-Url-1 = {http://dx.doi.org/10.1186/1758-2946-3-30}}

@article{Holliday2004,
	Abstract = {This paper evaluates the use of the fuzzy k-means clustering method for the clustering of files of 2D chemical structures. Simulated property prediction experiments with the Starlist file of logP values demonstrate that use of the fuzzy k-means method can, in some cases, yield results that are superior to those obtained with the conventional k-means method and with Ward's clustering method. Clustering of several small sets of agrochemical compounds demonstrate the ability of the fuzzy k-means method to highlight multicluster membership and to identify outlier compounds, although the former can be difficult to interpret in some cases.},
	Author = {Holliday, John D and Rodgers, Sarah L and Willett, Peter and Chen, Min-You and Mahfouf, Mahdi and Lawson, Kevin and Mullier, Graham},
	Doi = {10.1021/ci0342674},
	Isbn = {0095-2338},
	Issn = {0095-2338},
	Journal = {Journal of chemical information and computer sciences},
	Number = {3},
	Pages = {894--902},
	Pmid = {15154754},
	Title = {{Clustering files of chemical structures using the fuzzy k-means clustering method.}},
	Url = {http://www.ncbi.nlm.nih.gov/pubmed/15154754},
	Volume = {44},
	Year = {2004},
	Bdsk-Url-1 = {http://www.ncbi.nlm.nih.gov/pubmed/15154754},
	Bdsk-Url-2 = {http://dx.doi.org/10.1021/ci0342674}}

@article{Gamo2010,
	Abstract = {Malaria is a devastating infection caused by protozoa of the genus Plasmodium. Drug resistance is widespread, no new chemical class of antimalarials has been introduced into clinical practice since 1996 and there is a recent rise of parasite strains with reduced sensitivity to the newest drugs. We screened nearly 2 million compounds in GlaxoSmithKline's chemical library for inhibitors of P. falciparum, of which 13,533 were confirmed to inhibit parasite growth by at least 80{\%} at 2 microM concentration. More than 8,000 also showed potent activity against the multidrug resistant strain Dd2. Most (82{\%}) compounds originate from internal company projects and are new to the malaria community. Analyses using historic assay data suggest several novel mechanisms of antimalarial action, such as inhibition of protein kinases and host-pathogen interaction related targets. Chemical structures and associated data are hereby made public to encourage additional drug lead identification efforts and further research into this disease.},
	Author = {Gamo, Francisco-Javier and Sanz, Laura M and Vidal, Jaume and de Cozar, Cristina and Alvarez, Emilio and Lavandera, Jose-Luis and Vanderwall, Dana E and Green, Darren V S and Kumar, Vinod and Hasan, Samiul and Brown, James R and Peishoff, Catherine E and Cardon, Lon R and Garcia-Bustos, Jose F},
	Doi = {10.1038/nature09107},
	Isbn = {1476-4687 (Electronic)$\backslash$n0028-0836 (Linking)},
	Issn = {0028-0836},
	Journal = {Nature},
	Number = {7296},
	Pages = {305--310},
	Pmid = {20485427},
	Title = {{Thousands of chemical starting points for antimalarial lead identification.}},
	Url = {http://dx.doi.org/10.1038/nature09107},
	Volume = {465},
	Year = {2010},
	Bdsk-Url-1 = {http://dx.doi.org/10.1038/nature09107}}

@article{Calderon2011,
	Abstract = {In 2010, GlaxoSmithKline published the structures of 13533 chemical starting points for antimalarial lead identification. By using an agglomerative structural clustering technique followed by computational filters such as antimalarial activity, physicochemical properties, and dissimilarity to known antimalarial structures, we have identified 47 starting points for 13,533 2948 lead optimization. Their structures are provided. We invite potential collaborators to work with us to discover new clinical candidates.},
	Author = {Calder{\'{o}}n, F{\'{e}}lix and Barros, David and Bueno, Jos{\'{e}} Mar{\'{\i}}a and Coter{\'{o}}n, Jos{\'{e}} Miguel and Fern{\'{a}}ndez, Esther and Gamo, Francisco Javier and Lavandera, Jos{\'{e}} Lu{\'{\i}}s and Le{\'{o}}n, Mar{\'{\i}}a Luisa and MacDonald, Simon J F and Mallo, Araceli and Manzano, Pilar and Porras, Esther and Fiandor, Jos{\'{e}} Mar{\'{\i}}a and Castro, Julia},
	Doi = {10.1021/ml200135p},
	Isbn = {1948-5875},
	Issn = {19485875},
	Journal = {ACS Medicinal Chemistry Letters},
	Keywords = {Malaria,TCAMS,lead optimization,open innovation},
	Number = {10},
	Pages = {741--746},
	Pmid = {24900261},
	Title = {{An invitation to open innovation in malaria drug discovery: 47 quality starting points from the TCAMS}},
	Volume = {2},
	Year = {2011},
	Bdsk-Url-1 = {http://dx.doi.org/10.1021/ml200135p}}

@article{Coma2014,
	Abstract = {In this article, we describe two complementary data-mining approaches used to characterize the GlaxoSmithKline (GSK) natural-products set (NPS) based on information from the high-throughput screening (HTS) databases. Both methods rely on the aggregation and analysis of a large set of single-shot screening data for a number of biological assays, with the goal to reveal natural-product chemical motifs. One of them is an established method based on the data-driven clustering of compounds using a wide range of descriptors,(1) whereas the other method partitions and hierarchically clusters the data to identify chemical cores.(2,3) Both methods successfully find structural scaffolds that significantly hit different groups of discrete drug targets, compared with their relative frequency of demonstrating inhibitory activity in a large number of screens. We describe how these methods can be applied to unveil hidden information in large single-shot HTS data sets. Applied prospectively, this type of information could contribute to the design of new chemical templates for drug-target classes and guide synthetic efforts for lead optimization of tractable hits that are based on natural-product chemical motifs. Relevant findings for 7TM receptors (7TMRs), ion channels, class-7 transferases (protein kinases), hydrolases, and oxidoreductases will be discussed.},
	Author = {Coma, Isabel and Bandyopadhyay, Deepak and Diez, Emilio and Ruiz, Emilio Alvarez and {de Los Frailes}, Maria Teresa and Colmenarejo, Gonzalo},
	Doi = {10.1177/1087057114521463},
	Isbn = {1087057114521},
	Issn = {1552-454X},
	Journal = {Journal of biomolecular screening},
	Keywords = {activity relationships,computational chemistry,natural products screening,statistical analyses,structure},
	Number = {5},
	Pages = {749--757},
	Pmid = {24518065},
	Title = {{Mining Natural-Products Screening Data for Target-Class Chemical Motifs.}},
	Url = {http://www.ncbi.nlm.nih.gov/pubmed/24518065},
	Volume = {19},
	Year = {2014},
	Bdsk-Url-1 = {http://www.ncbi.nlm.nih.gov/pubmed/24518065},
	Bdsk-Url-2 = {http://dx.doi.org/10.1177/1087057114521463}}

@article{Mendgen:2012it,
	Abstract = {Rhodanines and related five-membered heterocycles with multiple heteroatoms have recently gained a reputation of being unselective compounds that appear as "frequent hitters" in screening campaigns and therefore have little value in drug discovery. However, this judgment appears to be based mostly on anecdotal evidence. Having identified various rhodanines and related compounds in screening campaigns, we decided to perform a systematic study on their promiscuity. An amount of 163 rhodanines, hydantoins, thiohydantoins, and thiazolidinediones were synthesized and tested against several targets. The compounds were also characterized with respect to aggregation and electrophilic reactivity, and the binding modes of rhodanines and related compounds in published X-ray cocrystal structures were analyzed. The results indicate that the exocyclic, double bonded sulfur atom in rhodanines and thiohydantoins, in addition to other structural features, offers a particularly high density of interaction sites for polar interactions and hydrogen bonds. This causes a promiscuous behavior at concentrations in the "screening range" but should not be regarded as a general knockout criterion that excludes such screening hits from further development. It is suggested that special criteria for target affinity and selectivity are applied to these classes of compounds and that their exceptional and potentially valuable biomolecular binding properties are consequently exploited in a useful way.},
	Author = {Mendgen, Thomas and Steuer, Christian and Klein, Christian D.},
	Date-Added = {2015-11-16 19:36:08 +0000},
	Date-Modified = {2015-11-16 19:36:08 +0000},
	Doi = {10.1021/jm201243p},
	Journal = {J.~Med.~Chem.},
	Journal-Full = {Journal of medicinal chemistry},
	Mesh = {Binding Sites; Crystallography, X-Ray; Enzyme Inhibitors; Hydantoins; Hydrogen Bonding; Ligands; Metalloproteases; Models, Molecular; Molecular Structure; Protein Binding; Rhodanine; Serine Proteases; Stereoisomerism; Structure-Activity Relationship; Thiazolidinediones; Transferases},
	Month = {Jan},
	Number = {2},
	Pages = {743--753},
	Pmid = {22077389},
	Pst = {ppublish},
	Title = {Privileged scaffolds or promiscuous binders: a comparative study on rhodanines and related heterocycles in medicinal chemistry},
	Volume = {55},
	Year = {2012},
	Bdsk-Url-1 = {http://dx.doi.org/10.1021/jm201243p}}

@article{Zhao:2015qd,
	Abstract = {INTRODUCTION: The term "privileged scaffold" was coined in 1988 and the strategy was to construct high-affinity ligands from core structures that can bind more than one receptor. Since then, the privileged scaffold-based design has evolved from a stand-alone technology to an integral component of various lead generation platforms.
AREAS COVERED: In this review, the authors discuss the applications of the privileged scaffold concept in current lead generation. Specifically, the authors cover the role that privileged scaffolds have played in the mass production of compounds to feed high-throughput screening (HTS) and its role in the design of ligands targeting protein-protein interactions, multiple ligands and warhead-based ligands. It is not the intention of the authors to review all privileged scaffolds known to date. Rather, the aim of this review is to highlight the strategic value of the concept of privileged scaffolds in various contemporary lead generation platforms.
EXPERT OPINION: The privileged scaffolds as described by the original definition proved abundant in the available chemical space. HTS and other screening methods, in addition to greatly enhanced compound collections, make privileged scaffold-based design less relevant in finding high-affinity ligands than originally envisioned. However, the principle of privileged scaffolds has greatly enhanced and empowered current lead generation technologies.},
	Author = {Zhao, Hongyu and Dietrich, Justin},
	Date-Added = {2015-11-16 19:27:33 +0000},
	Date-Modified = {2015-11-16 19:27:33 +0000},
	Doi = {10.1517/17460441.2015.1041496},
	Journal = {Expert Opin.~Drug.~Discov.},
	Journal-Full = {Expert opinion on drug discovery},
	Keywords = {binding warheads; high-throughput screening; multiple ligands; privileged scaffold; protein-protein interactions},
	Month = {Jul},
	Number = {7},
	Pages = {781--790},
	Pmid = {25959748},
	Pst = {ppublish},
	Title = {Privileged scaffolds in lead generation},
	Volume = {10},
	Year = {2015},
	Bdsk-Url-1 = {http://dx.doi.org/10.1517/17460441.2015.1041496}}

@article{Welsch:2010qy,
	Abstract = {This review explores the concept of using privileged scaffolds to identify biologically active compounds through building chemical libraries. We hope to accomplish three main objectives: to provide one of the most comprehensive listings of privileged scaffolds; to reveal through four selected examples the present state of the art in privileged scaffold library synthesis (in hopes of inspiring new and even more creative approaches); and also to offer some thoughts on how new privileged scaffolds might be identified and exploited.},
	Author = {Welsch, Matthew E. and Snyder, Scott A. and Stockwell, Brent R.},
	Date-Added = {2015-11-16 19:26:53 +0000},
	Date-Modified = {2015-11-16 19:26:53 +0000},
	Doi = {10.1016/j.cbpa.2010.02.018},
	Journal = {Curr.~Opin.~Chem.~Biol},
	Journal-Full = {Current opinion in chemical biology},
	Mesh = {Drug Delivery Systems; Drug Discovery; Humans; Models, Chemical; Pharmaceutical Preparations; Protein Binding; Receptors, Cytoplasmic and Nuclear; Small Molecule Libraries},
	Month = {Jun},
	Number = {3},
	Pages = {347--361},
	Pmc = {PMC2908274},
	Pmid = {20303320},
	Pst = {ppublish},
	Title = {Privileged scaffolds for library design and drug discovery},
	Volume = {14},
	Year = {2010},
	Bdsk-Url-1 = {http://dx.doi.org/10.1016/j.cbpa.2010.02.018}}

@article{Klekota:2008vn,
	Abstract = {MOTIVATION: Certain chemical substructures are present in many drugs. This has led to the claim of 'privileged' substructures which are predisposed to bioactivity. Because bias in screening library construction could explain this phenomenon, the existence of privilege has been controversial. RESULTS: Using diverse phenotypic assays, we defined bioactivity for multiple compound libraries. Many substructures were associated with bioactivity even after accounting for substructure prevalence in the library, thus validating the privileged substructure concept. Determinations of privilege were confirmed in independent assays and libraries. Our analysis also revealed 'underprivileged' substructures and 'conditional privilege'-rules relating combinations of substructure to bioactivity. Most previously reported substructures have been flat aromatic ring systems. Although we validated such substructures, we also identified three-dimensional privileged substructures. Most privileged substructures display a wide variety of substituents suggesting an entropic mechanism of privilege. Compounds containing privileged substructures had a doubled rate of bioactivity, suggesting practical consequences for pharmaceutical discovery.},
	Author = {Klekota, Justin and Roth, Frederick P.},
	Date-Added = {2015-11-16 19:25:57 +0000},
	Date-Modified = {2015-11-16 19:25:57 +0000},
	Doi = {10.1093/bioinformatics/btn479},
	Journal = {Bioinformatics},
	Journal-Full = {Bioinformatics (Oxford, England)},
	Mesh = {Animals; Cells, Cultured; Combinatorial Chemistry Techniques; Databases, Factual; Drug Design; Humans; Ligands; Pharmaceutical Preparations; Structure-Activity Relationship},
	Month = {Nov},
	Number = {21},
	Pages = {2518--2525},
	Pmc = {PMC2732283},
	Pmid = {18784118},
	Pst = {ppublish},
	Title = {Chemical substructures that enrich for biological activity},
	Volume = {24},
	Year = {2008},
	Bdsk-Url-1 = {http://dx.doi.org/10.1093/bioinformatics/btn479}}

@article{Lewell:1998aa,
	Abstract = {The use of combinatorial chemistry for the generation of new lead molecules is now a well established strategy in the drug discovery process. Central to the use of combinatorial chemistry is the design and availability of high quality building blocks which are likely to afford hits from the libraries that they generate. Herein we describe "RECAP" (Retrosynthetic Combinatorial Analysis Procedure), a new computational technique designed to address this building block issue. RECAP electronically fragments molecules based on chemical knowledge. When applied to databases of biologically active molecules this allows the identification of building block fragments rich in biologically recognized elements and privileged motifs and structures. This allows the design of building blocks and the synthesis of libraries rich in biological motifs. Application of RECAP to the Derwent World Drug Index (WDI) and the molecular fragments/building blocks that this generates are discussed. We also describe a WDI fragment knowledge base which we have built which stores the drug motifs and mention its potential application in structure based drug design programs.},
	Address = {1155 16TH ST, NW, WASHINGTON, DC 20036 USA},
	Author = {Lewell, X.Q. and Judd, D.B. and Watson, S.P. and Hann, M.M.},
	Date = {MAY-JUN 1998},
	Date-Added = {2015-11-11 14:54:36 +0000},
	Date-Modified = {2015-11-11 14:54:36 +0000},
	Doi = {10.1021/ci970429i},
	Journal = {J.~Chem.~Inf.~Comput.~Sci.},
	Keywords = {fragments; synthesis; murcko; framework},
	Pages = {511--522},
	Publisher = {AMER CHEMICAL SOC},
	Timescited = {113},
	Title = {{RECAP} - Retrosynthetic Combinatorial Analysis Procedure: A Powerful New Technique for Identifying Privileged Molecular Fragments with Useful Applications in Combinatorial Chemistry},
	Volume = {38},
	Year = {1998},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QJi4uLy4uL0RvY3VtZW50cy9hcnRpY2xlcy9jaTk3MDQyOWkucGRm0hcLGBlXTlMuZGF0YU8RAW4AAAAAAW4AAgAAA212IAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMU5bQNIKwAAABCNbQ1jaTk3MDQyOWkucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEI6SxLVXUgAAAAAAAAAAAAIAAwAACSAAAAAAAAAAAAAAAAAAAAAIYXJ0aWNsZXMAEAAIAADFObNTAAAAEQAIAADEtY+SAAAAAQAQABCNbQAKTIAACkxpAAB8EwACADBtdiA6VXNlcnM6cmd1aGE6RG9jdW1lbnRzOmFydGljbGVzOmNpOTcwNDI5aS5wZGYADgAcAA0AYwBpADkANwAwADQAMgA5AGkALgBwAGQAZgAPAAgAAwBtAHYAIAASACxVc2Vycy9yZ3VoYS9Eb2N1bWVudHMvYXJ0aWNsZXMvY2k5NzA0MjlpLnBkZgATAAEvAAAVAAIADP//AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOALcAvADEAjYCOAI9AkgCUQJfAmMCagJzAngChQKIApoCnQKiAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAqQ=}}

@article{Shun:2011sy,
	Abstract = {High-throughput screening (HTS) has achieved a dominant role in drug discovery over the past 2 decades. The goal of HTS is to identify active compounds (hits) by screening large numbers of diverse chemical compounds against selected targets and/or cellular phenotypes. The HTS process consists of multiple automated steps involving compound handling, liquid transfers, and assay signal capture, all of which unavoidably contribute to systematic variation in the screening data. The challenge is to distinguish biologically active compounds from assay variability. Traditional plate controls-based and non-controls-based statistical methods have been widely used for HTS data processing and active identification by both the pharmaceutical industry and academic sectors. More recently, improved robust statistical methods have been introduced, reducing the impact of systematic row/column effects in HTS data. To apply such robust methods effectively and properly, we need to understand their necessity and functionality. Data from 6 HTS case histories are presented to illustrate that robust statistical methods may sometimes be misleading and can result in more, rather than less, false positives or false negatives. In practice, no single method is the best hit detection method for every HTS data set. However, to aid the selection of the most appropriate HTS data-processing and active identification methods, the authors developed a 3-step statistical decision methodology. Step 1 is to determine the most appropriate HTS data-processing method and establish criteria for quality control review and active identification from 3-day assay signal window and DMSO validation tests. Step 2 is to perform a multilevel statistical and graphical review of the screening data to exclude data that fall outside the quality control criteria. Step 3 is to apply the established active criterion to the quality-assured data to identify the active compounds.},
	Author = {Shun, Tong Ying and Lazo, John S and Sharlow, Elizabeth R and Johnston, Paul A},
	Date-Added = {2015-11-11 14:39:08 +0000},
	Date-Modified = {2015-11-11 14:43:58 +0000},
	Journal = {J.~Biomol.~Screen.},
	Month = {Jan},
	Number = {1},
	Pages = {1--14},
	Title = {Identifying actives from {HTS} data sets: practical approaches for the selection of an appropriate HTS data-processing method and quality control review},
	Volume = {16},
	Year = {2011},
	Bdsk-Url-1 = {http://dx.doi.org/10.1177/1087057110389039}}

@article{Langer:2009mw,
	Abstract = {Drug discovery is complex and risky, and the chances of success are low. One starting point to discover a new drug is the selective screening of a collection of high value and good quality compounds. Selection of compounds for screening is one of the challenging initial steps in the drug discovery process and is crucial for the success of the project. Optimal selection will enhance the chances of successful hit finding with regard to both number and quality of hits. Several scenarios for compound selection can be envisaged, and are primarily driven by knowledge of the target. Deciding the most appropriate scenario is important and appropriate software packages and chemoinformatics tools are available for these purposes. After screening, researchers may face challenges in selecting the best hits for further optimization. Numerous chemoinformatics tools have emerged recently to address challenges in hit analysis, prioritization and optimization.},
	Author = {Langer, Thierry and Hoffmann, R{\'e}my and Bryant, Sharon and Lesur, Brigitte},
	Date-Added = {2015-11-11 14:38:31 +0000},
	Date-Modified = {2015-11-11 14:38:31 +0000},
	Doi = {10.1016/j.coph.2009.06.001},
	Journal = {Curr.~Opin.~Pharmacol.},
	Journal-Full = {Current opinion in pharmacology},
	Mesh = {Animals; Computer Simulation; Computer-Aided Design; Databases as Topic; Drug Design; Drug Discovery; High-Throughput Screening Assays; Humans; Ligands; Models, Molecular; Small Molecule Libraries; Structure-Activity Relationship},
	Month = {Oct},
	Number = {5},
	Pages = {589--593},
	Pmid = {19576852},
	Pst = {ppublish},
	Title = {Hit finding: towards 'smarter' approaches},
	Volume = {9},
	Year = {2009},
	Bdsk-Url-1 = {http://dx.doi.org/10.1016/j.coph.2009.06.001}}

@article{Pu:2012wf,
	Abstract = {In this paper, we describe the implementation and evaluation of a cluster-based enrichment strategy to call hits from a high-throughput screen using a typical cell-based assay of 160,000 chemical compounds. Our focus is on statistical properties of the prospective design choices throughout the analysis, including how to choose the number of clusters for optimal power, the choice of test statistic, the significance thresholds for clusters and the activity threshold for candidate hits, how to rank selected hits for carry-forward to the confirmation screen, and how to identify confirmed hits in a data-driven manner. Whereas previously the literature has focused on choice of test statistic or chemical descriptors, our studies suggest that cluster size is the more important design choice. We recommend clusters to be ranked by enrichment odds ratio, not by p-value. Our conceptually simple test statistic is seen to identify the same set of hits as more complex scoring methods proposed in the literature do. We prospectively confirm that such a cluster-based approach can outperform the naive top X approach and estimate that we improved confirmation rates by about 31.5% from 813 using the top X approach to 1187 using our cluster-based method.},
	Author = {Pu, Minya and Hayashi, Tomoko and Cottam, Howard and Mulvaney, Joseph and Arkin, Michelle and Corr, Maripat and Carson, Dennis and Messer, Karen},
	Date-Added = {2015-11-11 14:35:19 +0000},
	Date-Modified = {2015-11-11 14:35:32 +0000},
	Doi = {10.1002/sim.5455},
	Journal = {Stat.~Med.},
	Journal-Full = {Statistics in medicine},
	Mesh = {Antineoplastic Agents; Cluster Analysis; Data Interpretation, Statistical; Drug Discovery; False Positive Reactions; High-Throughput Screening Assays; Humans; Odds Ratio; Prospective Studies; Research Design},
	Month = {Dec},
	Number = {30},
	Pages = {4175--4189},
	Pmc = {PMC3635947},
	Pmid = {22763983},
	Pst = {ppublish},
	Title = {Analysis of high-throughput screening assays using cluster enrichment},
	Volume = {31},
	Year = {2012},
	Bdsk-Url-1 = {http://dx.doi.org/10.1002/sim.5455}}

@article{Peng:2013qp,
	Author = {Peng, Z. and Gillespie, P. and Weisel, M. and So, S.S. and So, W.V. and Kondru, R. and Narayanan, A. and Hermann, J.C.},
	Date-Added = {2015-11-11 14:10:10 +0000},
	Date-Modified = {2015-11-11 14:12:19 +0000},
	Journal = {Mol.~Inf.},
	Number = {4},
	Pages = {337--345},
	Title = {A Crowd-Based Process and Tool for {HTS} Hit Triage},
	Volume = {32},
	Year = {2013}}

@article{Dahlin:2015eu,
	Abstract = {Nonspecific bioactivity and assay artifacts have gained increasing attention in recent years. This focus has arisen primarily from the publication of a set of chemical substructures, termed pan assay interference compounds (PAINS), which are associated with promiscuous bioactivity and assay interference in real and virtual high-throughput screening (HTS) campaigns. Despite an increasing awareness in the HTS and medicinal chemistry communities about the liabilities of these compounds, articles featuring PAINS and PAINS-like compounds are still being published. In this perspective, we describe some of the factors we believe are driving this resource-sapping trend. We also provide what we hope are helpful insights that may lead to the earlier recognition of these generally nontranslatable compounds, thus preventing the propagation of PAINS-full costly research.},
	Author = {Dahlin, Jayme L and Walters, Michael A},
	Date-Added = {2015-11-11 13:47:45 +0000},
	Date-Modified = {2015-11-11 13:49:19 +0000},
	Doi = {10.1089/adt.2015.674},
	Journal = {Assay Drug Dev.~Technol.},
	Journal-Full = {Assay and drug development technologies},
	Month = {Oct},
	Pmid = {26496388},
	Pst = {aheadofprint},
	Title = {How to Triage PAINS},
	Year = {2015},
	Bdsk-Url-1 = {http://dx.doi.org/10.1089/adt.2015.674}}

@article{Dahlin:2014fp,
	Abstract = {It is increasingly clear that academic high-throughput screening (HTS) and virtual HTS triage suffers from a lack of scientists trained in the art and science of early drug discovery chemistry. Many recent publications report the discovery of compounds by screening that are most likely artifacts or promiscuous bioactive compounds, and these results are not placed into the context of previous studies. For HTS to be most successful, it is our contention that there must exist an early partnership between biologists and medicinal chemists. Their combined skill sets are necessary to design robust assays and efficient workflows that will weed out assay artifacts, false positives, promiscuous bioactive compounds and intractable screening hits, efforts that ultimately give projects a better chance at identifying truly useful chemical matter. Expertise in medicinal chemistry, cheminformatics and purification sciences (analytical chemistry) can enhance the post-HTS triage process by quickly removing these problematic chemotypes from consideration, while simultaneously prioritizing the more promising chemical matter for follow-up testing. It is only when biologists and chemists collaborate effectively that HTS can manifest its full promise.},
	Author = {Dahlin, Jayme L. and Walters, Michael A.},
	Date-Added = {2015-11-11 13:46:57 +0000},
	Date-Modified = {2015-11-11 13:47:09 +0000},
	Doi = {10.4155/fmc.14.60},
	Journal = {Future Med.~Chem},
	Journal-Full = {Future medicinal chemistry},
	Mesh = {Animals; Chemistry, Pharmaceutical; Drug Discovery; High-Throughput Screening Assays; Humans; Informatics},
	Month = {Jul},
	Number = {11},
	Pages = {1265--1290},
	Pmc = {PMC4465542},
	Pmid = {25163000},
	Pst = {ppublish},
	Title = {The essential roles of chemistry in high-throughput screening triage},
	Volume = {6},
	Year = {2014},
	Bdsk-Url-1 = {http://dx.doi.org/10.4155/fmc.14.60}}

@article{Macarron:2011qv,
	Abstract = {High-throughput screening (HTS) has been postulated in several quarters to be a contributory factor to the decline in productivity in the pharmaceutical industry. Moreover, it has been blamed for stifling the creativity that drug discovery demands. In this article, we aim to dispel these myths and present the case for the use of HTS as part of a proven scientific tool kit, the wider use of which is essential for the discovery of new chemotypes.},
	Author = {Macarron, Ricardo and Banks, Martyn N. and Bojanic, Dejan and Burns, David J and Cirovic, Dragan A and Garyantes, Tina and Green, Darren V S and Hertzberg, Robert P. and Janzen, William P. and Paslay, Jeff W. and Schopfer, Ulrich and Sittampalam, G Sitta},
	Date-Added = {2015-11-11 13:35:02 +0000},
	Date-Modified = {2015-11-11 13:35:33 +0000},
	Doi = {10.1038/nrd3368},
	Journal = {Nat.~Rev.~Drug Discov.},
	Journal-Full = {Nature reviews. Drug discovery},
	Mesh = {Animals; Biomedical Research; Drug Design; Drug Evaluation, Preclinical; Humans; Small Molecule Libraries},
	Month = {Mar},
	Number = {3},
	Pages = {188--195},
	Pmid = {21358738},
	Pst = {ppublish},
	Title = {Impact of high-throughput screening in biomedical research},
	Volume = {10},
	Year = {2011},
	Bdsk-Url-1 = {http://dx.doi.org/10.1038/nrd3368}}

@article{Cox:2012qy,
	Abstract = {The selection of the highest quality chemical matter from high throughput screening (HTS) is the ultimate aim of any triage process. Typically there are many hundreds or thousands of hits capable of modulating a given biological target in HTS with a wide range of physicochemical properties that should be taken into consideration during triage. Given the multitude of physicochemical properties that define drug-like space, a system needs to be in place that allows for a rapid selection of chemical matter based on a prioritized range of these properties. With this goal in mind, we have developed a tool, coined Abbott Physicochemical Tiering (APT) that enables hit prioritization based on ranges of these important physicochemical properties. This tool is now used routinely at Abbott to help prioritize hits out of HTS during the triage process. Herein we describe how this tool was developed and validated using Abbott internal high throughput ADME data (HT-ADME).},
	Author = {Cox, Philip B and Gregg, Robert J and Vasudevan, Anil},
	Date-Added = {2015-11-11 13:32:58 +0000},
	Date-Modified = {2015-11-11 13:32:58 +0000},
	Doi = {10.1016/j.bmc.2012.05.047},
	Journal = {Bioorg Med Chem},
	Journal-Full = {Bioorganic \& medicinal chemistry},
	Mesh = {Drug Evaluation, Preclinical; Drug Industry; High-Throughput Screening Assays},
	Month = {Jul},
	Number = {14},
	Pages = {4564-73},
	Pmid = {22727778},
	Pst = {ppublish},
	Title = {Abbott Physicochemical Tiering (APT)--a unified approach to HTS triage},
	Volume = {20},
	Year = {2012},
	Bdsk-Url-1 = {http://dx.doi.org/10.1016/j.bmc.2012.05.047}}

@article{Clark2010FragHier,
	Abstract = {Drug discovery projects often involve organizing compounds in the form of a hierarchical tree, where each node is a substructure fragment shared by all of its descendent nodes. A method is described for producing 2D depiction layout coordinates for each of the nodes in such a tree, ensuring that common fragments within molecular structures are drawn in an identical way, and arranged with a consistent orientation. This is achieved by first deriving a common numbering scheme for common fragments, then using this scheme to redepict each of the molecules, one fragment at a time, so that common fragments have common depiction motifs. Once complete, the distinct root branches can be overlaid onto each other, after which all of the fragments and whole molecules have a common layout and orientation. Several methods are described for preparing visual representations of molecular structure hierarchies alongside activity information. Combining high level tree display and structure depiction showing common features readily facilitates insight into structure-activity relationships.},
	Author = {Clark, A. M.},
	Date-Added = {2015-11-11 13:31:34 +0000},
	Date-Modified = {2015-11-11 13:31:34 +0000},
	Journal = {J Chem Inf Model},
	Month = {Jan},
	Note = {[PubMed Central:\href{http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2810838}{PMC2810838}] [DOI:\href{http://dx.doi.org/10.1021/ci900350h}{10.1021/ci900350h}] [PubMed:\href{http://www.ncbi.nlm.nih.gov/pubmed/20038186}{20038186}]},
	Number = {1},
	Pages = {37--46},
	Title = {{2{D} depiction of fragment hierarchies}},
	Volume = {50},
	Year = {2010}}

@article{ClarkLabute2008SAReport,
	Abstract = {A method is presented for the detection and analysis of multiple common scaffolds for small collections of pharmaceutically relevant molecules that share a set of common structural motifs. The input consists of the molecules themselves, possibly some of the scaffolds, and possibly information about the relation between the substitution points of these scaffolds. Three new algorithms are presented: multiple scaffold detection, common scaffold alignment, and scaffold substructure assignment. Each of these steps is relevant for cases when either none, some, or all information about the common scaffolds and their substitution patterns is available. Each of these problems must be solved in an optimal way in order to produce useful structure-activity correlations. The output consists of a collection of scaffolds, a common numbering system, and a unique mapping of each molecule to a single scaffold substructure. This information can then be used to produce data for structure-activity analysis of medicinal chemistry project databases.},
	Author = {Clark, A. M. and Labute, P.},
	Date-Added = {2015-11-11 13:31:34 +0000},
	Date-Modified = {2015-11-11 14:02:06 +0000},
	Journal = {J.~Med.~Chem.},
	Month = {Jan},
	Number = {2},
	Pages = {469--483},
	Title = {{{D}etection and assignment of common scaffolds in project databases of lead molecules}},
	Volume = {52},
	Year = {2009}}

@article{Yeo2012substructProfile,
	Abstract = {Compounds known to be potent against a specific protein target may potentially contain a signature profile of common substructures that is highly correlated to their potency. These substructure profiles may be useful in enriching compound libraries or for prioritizing compounds against a specific protein target. With this objective in mind, a set of compounds with known potency against six selected kinases (2 each from 3 kinase families) was used to generate binary molecular fingerprints. Each fingerprint key represents a substructure that is found within a compound and the frequency with which the fingerprint occurs was then tabulated. Thereafter, a frequent pattern mining technique was applied with the aim of uncovering substructures that are not only well represented among known potent inhibitors but are also unrepresented among known inactive compounds and vice versa. Substructure profiles that are representative of potent inhibitors against each of the 3 kinase families were thus extracted. Based on our validation results, these substructure profiles demonstrated significant enrichment for highly potent compounds against their respective kinase targets. The advantages of using our approach over conventional methods in analyzing such datasets and its application in the mining of substructures for enriching compound libraries are presented.},
	Author = {Yeo, W. K. and Go, M. L. and Nilar, S.},
	Date-Added = {2015-11-11 13:31:34 +0000},
	Date-Modified = {2015-11-11 13:31:34 +0000},
	Journal = {J. Comput. Aided Mol. Des.},
	Month = {Oct},
	Note = {[DOI:\href{http://dx.doi.org/10.1007/s10822-012-9604-8}{10.1007/s10822-012-9604-8}] [PubMed:\href{http://www.ncbi.nlm.nih.gov/pubmed/22983491}{22983491}]},
	Number = {10},
	Pages = {1127--1141},
	Title = {{{E}xtraction and validation of substructure profiles for enriching compound libraries}},
	Volume = {26},
	Year = {2012}}

@article{Wawer2010review,
	Abstract = {Computational data mining and visualization techniques play a central part in the extraction of structure-activity relationship (SAR) information from compound sets including high-throughput screening data. Standard statistical and classification techniques can be used to organize data sets and evaluate the chemical neighborhood of potent hits; however, such methods are limited in their ability to extract complex SAR patterns from data sets and make them readily accessible to medicinal chemists. Therefore, new approaches and data structures are being developed that explicitly focus on molecular structure and its relationship to biological activity across multiple targets. Here, we review standard techniques for compound data analysis and describe new data structures and computational tools for SAR mining of large compound data sets.},
	Author = {Wawer, M. and Lounkine, E. and Wassermann, A. M. and Bajorath, J.},
	Date-Added = {2015-11-11 13:31:34 +0000},
	Date-Modified = {2016-01-05 17:13:46 +0000},
	Journal = {Drug Discov.~Today},
	Month = {Aug},
	Note = {[DOI:\href{http://dx.doi.org/10.1016/j.drudis.2010.06.004}{10.1016/j.drudis.2010.06.004}] [PubMed:\href{http://www.ncbi.nlm.nih.gov/pubmed/20547243}{20547243}]},
	Number = {15-16},
	Pages = {630--639},
	Title = {{{D}ata structures and computational tools for the extraction of {S}{A}{R} information from large compound sets}},
	Volume = {15},
	Year = {2010}}

@article{Gupta-Ostermann2012mining,
	Abstract = {The transfer of SAR information from one analog series to another is a difficult, yet highly attractive task in medicinal chemistry. At present, the evaluation of SAR transfer potential from a data mining perspective is still in its infancy. Only recently, a first computational approach has been introduced to evaluate SAR transfer events. Here, a substructure relationship-based molecular network representation has been used as a starting point to systematically identify SAR transfer series in large compound data sets. For this purpose, a methodology is introduced that consists of two stages. For graph mining, an algorithm has been designed that extracts all parallel series from compound data sets. A parallel series is formed by two series of analogs with different core structures but pairwise corresponding substitution patterns. The SAR transfer potential of identified parallel series is then evaluated using a scoring function that emphasizes corresponding potency progression over many analog pairs and large potency ranges. The substructure relationship-based molecular network in combination with the graph mining algorithm currently represents the only generally applicable approach to systematically detect SAR transfer events in large compound data sets. The combined approach has been evaluated on a large number of compound data sets and shown to systematically identify SAR transfer series.},
	Author = {Gupta-Ostermann, D. and Wawer, M. and Wassermann, A. M. and Bajorath, J.},
	Date-Added = {2015-11-11 13:31:34 +0000},
	Date-Modified = {2015-11-11 13:31:34 +0000},
	Journal = {J Chem Inf Model},
	Month = {Apr},
	Note = {[DOI:\href{http://dx.doi.org/10.1021/ci300071y}{10.1021/ci300071y}] [PubMed:\href{http://www.ncbi.nlm.nih.gov/pubmed/22436016}{22436016}]},
	Title = {{{G}raph {M}ining for {S}{A}{R} {T}ransfer {S}eries}},
	Year = {2012}}

@article{Wawer2011substruct,
	Abstract = {The systematic extraction of structure-activity relationship (SAR) information from large and diverse compound data sets depends on the application of computational analysis methods. Irrespective of the methodological details, the ultimate goal of large-scale SAR analysis is to identify most informative compounds and rationalize structural changes that determine SAR behavior. Such insights provide a basis for further chemical exploration. Herein we introduce the first graphical SAR analysis method that globally organizes large compound data sets on the basis of local structural relationships, hence providing an immediate access to important structural modifications and SAR determinants.},
	Author = {Wawer, M. and Bajorath, J.},
	Date-Added = {2015-11-11 13:31:34 +0000},
	Date-Modified = {2015-11-11 13:31:34 +0000},
	Journal = {J. Med. Chem.},
	Month = {Apr},
	Note = {[DOI:\href{http://dx.doi.org/10.1021/jm200026b}{10.1021/jm200026b}] [PubMed:\href{http://www.ncbi.nlm.nih.gov/pubmed/21443196}{21443196}]},
	Number = {8},
	Pages = {2944--2951},
	Title = {{{L}ocal structural changes, global data views: graphical substructure-activity relationship trailing}},
	Volume = {54},
	Year = {2011}}

@article{Ripphausen2011tolerance,
	Abstract = {It is well appreciated that the results of ligand-based virtual screening (LBVS) are much influenced by methodological details, given the generally strong compound class dependence of LBVS methods. It is less well understood to what extent structure-activity relationship (SAR) characteristics might influence the outcome of LBVS. We have assessed the hypothesis that the success of prospective LBVS depends on the SAR tolerance of screening targets, in addition to methodological aspects. In this context, SAR tolerance is rationalized as the ability of a target protein to specifically interact with series of structurally diverse active compounds. In compound data sets, SAR tolerance articulates itself as SAR continuity, i.e., the presence of structurally diverse compounds having similar potency. In order to analyze the role of SAR tolerance for LBVS, activity landscape representations of compounds active against 16 different target proteins were generated for which successful LBVS applications were reported. In all instances, the activity landscapes of known active compounds contained multiple regions of local SAR continuity. When analyzing the location of newly identified LBVS hits and their SAR environments, we found that these hits almost exclusively mapped to regions of distinct local SAR continuity. Taken together, these findings indicate the presence of a close link between SAR tolerance at the target level, SAR continuity at the ligand level, and the probability of LBVS success.},
	Author = {Ripphausen, P. and Nisius, B. and Wawer, M. and Bajorath, J.},
	Date-Added = {2015-11-11 13:31:34 +0000},
	Date-Modified = {2015-11-11 13:31:34 +0000},
	Journal = {J Chem Inf Model},
	Month = {Apr},
	Note = {[DOI:\href{http://dx.doi.org/10.1021/ci200064c}{10.1021/ci200064c}] [PubMed:\href{http://www.ncbi.nlm.nih.gov/pubmed/21438544}{21438544}]},
	Number = {4},
	Pages = {837--842},
	Title = {{{R}ationalizing the role of {S}{A}{R} tolerance for ligand-based virtual screening}},
	Volume = {51},
	Year = {2011}}

@article{Wawer2009SARpathTree,
	Abstract = {A data mining approach is introduced that automatically extracts SAR information from high-throughput screening data sets and that helps to select active compounds for chemical exploration and hit-to-lead projects. SAR pathways are systematically identified consisting of sequences of similar active compounds with gradual increases in potency. Fully enumerated SAR pathway sets are subjected to pathway scoring, filtering, and mining, and pathways with the most significant SAR information content are prioritized. High-scoring SAR pathways often reveal activity cliffs contained in screening data. Subsets of SAR pathways are analyzed in SAR trees that make it possible to identify microenvironments of significant SAR discontinuity from which hits are preferentially selected. SAR trees of alternative pathways leading to activity cliffs identify key compounds and help to develop chemically intuitive SAR hypotheses.},
	Author = {Wawer, M. and Bajorath, J.},
	Date-Added = {2015-11-11 13:31:34 +0000},
	Date-Modified = {2015-11-11 13:31:34 +0000},
	Journal = {ChemMedChem},
	Month = {Sep},
	Note = {[DOI:\href{http://dx.doi.org/10.1002/cmdc.200900222}{10.1002/cmdc.200900222}] [PubMed:\href{http://www.ncbi.nlm.nih.gov/pubmed/19621333}{19621333}]},
	Number = {9},
	Pages = {1431--1438},
	Title = {{{S}ystematic extraction of structure-activity relationship information from biological screening data}},
	Volume = {4},
	Year = {2009}}

@article{Wawer2008NSG,
	Abstract = {The study of structure-activity relationships (SARs) of small molecules is of fundamental importance in medicinal chemistry and drug design. Here, we introduce an approach that combines the analysis of similarity-based molecular networks and SAR index distributions to identify multiple SAR components present within sets of active compounds. Different compound classes produce molecular networks of distinct topology. Subsets of compounds related by different local SARs are often organized in small communities in networks annotated with potency information. Many local SAR communities are not isolated but connected by chemical bridges, i.e., similar molecules occurring in different local SAR contexts. The analysis makes it possible to relate local and global SAR features to each other and identify key compounds that are major determinants of SAR characteristics. In many instances, such compounds represent start and end points of chemical optimization pathways and aid in the selection of other candidates from their communities.},
	Author = {Wawer, M. and Peltason, L. and Weskamp, N. and Teckentrup, A. and Bajorath, J.},
	Date-Added = {2015-11-11 13:31:34 +0000},
	Date-Modified = {2015-11-11 13:31:34 +0000},
	Journal = {J. Med. Chem.},
	Month = {Oct},
	Note = {[DOI:\href{http://dx.doi.org/10.1021/jm800867g}{10.1021/jm800867g}] [PubMed:\href{http://www.ncbi.nlm.nih.gov/pubmed/18798611}{18798611}]},
	Number = {19},
	Pages = {6075--6084},
	Title = {{{S}tructure-activity relationship anatomy by network-like similarity graphs and local structure-activity relationship indices}},
	Volume = {51},
	Year = {2008}}

@article{Swamidass2011DOP,
	Abstract = {In high-throughput screens (HTS) of small molecules for activity in an in vitro assay, it is common to search for active scaffolds, with at least one example successfully confirmed as an active. The number of active scaffolds better reflects the success of the screen than the number of active molecules. Many existing algorithms for deciding which hits should be sent for confirmatory testing neglect this concern.\\ We derived a new extension of a recently proposed economic framework, diversity-oriented prioritization (DOP), that aims-by changing which hits are sent for confirmatory testing-to maximize the number of scaffolds with at least one confirmed active. In both retrospective and prospective experiments, DOP accurately predicted the number of scaffold discoveries in a batch of confirmatory experiments, improved the rate of scaffold discovery by 8-17\%, and was surprisingly robust to the size of the confirmatory test batches. As an extension of our previously reported economic framework, DOP can be used to decide the optimal number of hits to send for confirmatory testing by iteratively computing the cost of discovering an additional scaffold, the marginal cost of discovery.\\ swamidass@wustl.edu\\ Supplementary data are available at Bioinformatics online.},
	Author = {Swamidass, S. J. and Calhoun, B. T. and Bittker, J. A. and Bodycombe, N. E. and Clemons, P. A.},
	Date-Added = {2015-11-11 13:31:34 +0000},
	Date-Modified = {2015-11-11 13:31:34 +0000},
	Journal = {Bioinformatics},
	Month = {Aug},
	Number = {16},
	Pages = {2271--2278},
	Title = {{{E}nhancing the rate of scaffold discovery with diversity-oriented prioritization}},
	Volume = {27},
	Year = {2011}}

@article{Matlock2013SNG,
	Abstract = {Scaffold network generator (SNG) is an open-source command-line utility that computes the hierarchical network of scaffolds that define a large set of input molecules. Scaffold networks are useful for visualizing, analysing and understanding the chemical data that is increasingly available through large public repositories like PubChem. For example, some groups have used scaffold networks to identify missed-actives in high-throughput screens of small molecules with bioassays. Substantially improving on existing software, SNG is robust enough to work on millions of molecules at a time with a simple command-line interface.\\ SNG is accessible at http://swami.wustl.edu/sng},
	Author = {Matlock, M. K. and Zaretzki, J. M. and Swamidass, S. J.},
	Date-Added = {2015-11-11 13:31:34 +0000},
	Date-Modified = {2015-11-11 13:31:34 +0000},
	Journal = {Bioinformatics},
	Month = {Oct},
	Number = {20},
	Pages = {2655--2656},
	Title = {{{S}caffold network generator: a tool for mining molecular structures}},
	Volume = {29},
	Year = {2013}}

@article{Lounkine2010SARANEA,
	Abstract = {We introduce SARANEA, an open-source Java application for interactive exploration of structure-activity relationship (SAR) and structure-selectivity relationship (SSR) information in compound sets of any source. SARANEA integrates various SAR and SSR analysis functions and utilizes a network-like similarity graph data structure for visualization. The program enables the systematic detection of activity and selectivity cliffs and corresponding key compounds across multiple targets. Advanced SAR analysis functions implemented in SARANEA include, among others, layered chemical neighborhood graphs, cliff indices, selectivity trees, editing functions for molecular networks and pathways, bioactivity summaries of key compounds, and markers for bioactive compounds having potential side effects. We report the application of SARANEA to identify SAR and SSR determinants in different sets of serine protease inhibitors. It is found that key compounds can influence SARs and SSRs in rather different ways. Such compounds and their SAR/SSR characteristics can be systematically identified and explored using SARANEA. The program and source code are made freely available under the GNU General Public License.},
	Author = {Lounkine, E. and Wawer, M. and Wassermann, A. M. and Bajorath, J.},
	Date-Added = {2015-11-11 13:31:34 +0000},
	Date-Modified = {2016-01-05 17:13:41 +0000},
	Journal = {J.~Chem.~Inf.~Model.},
	Month = {Jan},
	Number = {1},
	Pages = {68--78},
	Title = {{{S}{A}{R}{A}{N}{E}{A}: a freely available program to mine structure-activity and structure-selectivity relationship information in compound data sets}},
	Volume = {50},
	Year = {2010}}

@article{GlickJacoby2011review,
	Author = {Glick, M. and Jacoby, E.},
	Date-Added = {2015-11-11 13:31:34 +0000},
	Date-Modified = {2015-11-11 13:31:34 +0000},
	Journal = {Curr Opin Chem Biol},
	Month = {Aug},
	Number = {4},
	Pages = {540--546},
	Title = {{{T}he role of computational methods in the identification of bioactive compounds}},
	Volume = {15},
	Year = {2011}}

@article{Sink2010FalsePos,
	Author = {Sink, R. and Gobec, S. and Pe?ar, S. and Zega, A.},
	Date-Added = {2015-11-11 13:31:34 +0000},
	Date-Modified = {2016-01-05 17:14:22 +0000},
	Journal = {Curr.~Med.~Chem.},
	Number = {34},
	Pages = {4231--4255},
	Title = {{{F}alse positives in the early stages of drug discovery}},
	Volume = {17},
	Year = {2010}}

@article{Duffy2012reviewLeadID,
	Author = {Duffy, B. C. and Zhu, L. and Decornez, H. and Kitchen, D. B.},
	Date-Added = {2015-11-11 13:31:34 +0000},
	Date-Modified = {2015-11-11 13:31:34 +0000},
	Journal = {Bioorg. Med. Chem.},
	Month = {Sep},
	Number = {18},
	Pages = {5324--5342},
	Title = {{{E}arly phase drug discovery: cheminformatics and computational techniques in identifying lead series}},
	Volume = {20},
	Year = {2012}}

@article{Petrone2012HTSFP,
	Author = {Petrone, P. M. and Simms, B. and Nigsch, F. and Lounkine, E. and Kutchukian, P. and Cornett, A. and Deng, Z. and Davies, J. W. and Jenkins, J. L. and Glick, M.},
	Date-Added = {2015-11-11 13:31:34 +0000},
	Date-Modified = {2016-01-05 17:13:34 +0000},
	Journal = {{ACS} Chem.~Biol.},
	Month = {Aug},
	Number = {8},
	Pages = {1399--1409},
	Title = {{{R}ethinking molecular similarity: comparing compounds on the basis of biological activity}},
	Volume = {7},
	Year = {2012}}

@article{Prummer2012hypTest,
	Author = {Prummer, M.},
	Date-Added = {2015-11-11 13:31:34 +0000},
	Date-Modified = {2015-11-11 13:31:34 +0000},
	Journal = {J Biomol Screen},
	Month = {Apr},
	Number = {4},
	Pages = {519--529},
	Title = {{{H}ypothesis testing in high-throughput screening for drug discovery}},
	Volume = {17},
	Year = {2012}}

@article{Strobelt2012HiTSEE,
	Abstract = {We present HiTSEE (High-Throughput Screening Exploration Environment), a visualization tool for the analysis of large chemical screens used to examine biochemical processes. The tool supports the investigation of structure-activity relationships (SAR analysis) and, through a flexible interaction mechanism, the navigation of large chemical spaces. Our approach is based on the projection of one or a few molecules of interest and the expansion around their neighborhood and allows for the exploration of large chemical libraries without the need to create an all encompassing overview of the whole library. We describe the requirements we collected during our collaboration with biologists and chemists, the design rationale behind the tool, and two case studies on different datasets. The described integration (HiTSEE KNIME) into the KNIME platform allows additional flexibility in adopting our approach to a wide range of different biochemical problems and enables other research groups to use HiTSEE.},
	Author = {Strobelt, H. and Bertini, E. and Braun, J. and Deussen, O. and Groth, U. and Mayer, T. U. and Merhof, D.},
	Date-Added = {2015-11-11 13:31:34 +0000},
	Date-Modified = {2015-11-11 13:31:34 +0000},
	Journal = {BMC Bioinformatics},
	Pages = {S4},
	Title = {{{H}i{T}{S}{E}{E} {K}{N}{I}{M}{E}: a visualization tool for hit selection and analysis in high-throughput screening experiments for the {K}{N}{I}{M}{E} platform}},
	Volume = {13 Suppl 8},
	Year = {2012}}

@article{Wetzel2009ScafHunt,
	Abstract = {We describe Scaffold Hunter, a highly interactive computer-based tool for navigation in chemical space that fosters intuitive recognition of complex structural relationships associated with bioactivity. The program reads compound structures and bioactivity data, generates compound scaffolds, correlates them in a hierarchical tree-like arrangement, and annotates them with bioactivity. Brachiation along tree branches from structurally complex to simple scaffolds allows identification of new ligand types. We provide proof of concept for pyruvate kinase.},
	Author = {Wetzel, S. and Klein, K. and Renner, S. and Rauh, D. and Oprea, T. I. and Mutzel, P. and Waldmann, H.},
	Date-Added = {2015-11-11 13:31:34 +0000},
	Date-Modified = {2015-11-11 13:31:34 +0000},
	Doi = {10.1038/nchembio.187},
	Journal = {Nat. Chem. Biol.},
	Month = {Aug},
	Number = {8},
	Pages = {581--583},
	Title = {{{I}nteractive exploration of chemical space with {S}caffold {H}unter}},
	Volume = {5},
	Year = {2009},
	Bdsk-Url-1 = {http://dx.doi.org/10.1038/nchembio.187}}

@article{Lounkine2011ActAware,
	Abstract = {From a medicinal chemistry point of view, one of the primary goals of high throughput screening (HTS) hit list assessment is the identification of chemotypes with an informative structure-activity relationship (SAR). Such chemotypes may enable optimization of the primary potency, as well as selectivity and phamacokinetic properties. A common way to prioritize them is molecular clustering of the hits. Typical clustering techniques, however, rely on a general notion of chemical similarity or standard rules of scaffold decomposition and are thus insensitive to molecular features that are enriched in biologically active compounds. This hinders SAR analysis, because compounds sharing the same pharmacophore might not end up in the same cluster and thus are not directly compared to each other by the medicinal chemist. Similarly, common chemotypes that are not related to activity may contaminate clusters, distracting from important chemical motifs. We combined molecular similarity and Bayesian models and introduce (I) a robust, activity-aware clustering approach and (II) a feature mapping method for the elucidation of distinct SAR determinants in polypharmacologic compounds. We evaluated the method on 462 dose-response assays from the Pubchem Bioassay repository. Activity-aware clustering grouped compounds sharing molecular cores that were specific for the target or pathway at hand, rather than grouping inactive scaffolds commonly found in compound series. Many of these core structures we also found in literature that discussed SARs of the respective targets. A numerical comparison of cores allowed for identification of the structural prerequisites for polypharmacology, i.e., distinct bioactive regions within a single compound, and pointed toward selectivity-conferring medchem strategies. The method presented here is generally applicable to any type of activity data and may help bridge the gap between hit list assessment and designing a medchem strategy.},
	Author = {Lounkine, E. and Nigsch, F. and Jenkins, J. L. and Glick, M.},
	Date-Added = {2015-11-11 13:31:34 +0000},
	Date-Modified = {2016-01-05 17:13:23 +0000},
	Doi = {10.1021/ci2004994},
	Journal = {J.~Chem.~Inf.~Model.},
	Month = {Dec},
	Number = {12},
	Pages = {3158--3168},
	Title = {{{A}ctivity-aware clustering of high throughput screening data and elucidation of orthogonal structure-activity relationships}},
	Volume = {51},
	Year = {2011},
	Bdsk-Url-1 = {http://dx.doi.org/10.1021/ci2004994}}

@article{Renner2011CollDesign,
	Abstract = {The design of a high-quality screening collection is of utmost importance for the early drug-discovery process and provides, in combination with high-quality assay systems, the foundation of future discoveries. Herein, we review recent trends and observations to successfully expand the access to bioactive chemical space, including the feedback from hit assessment interviews of high-throughput screening campaigns; recent successes with chemogenomics target family approaches, the identification of new relevant target/domain families, diversity-oriented synthesis and new emerging compound classes, and non-classical approaches, such as fragment-based screening and DNA-encoded chemical libraries. The role of in silico library design approaches are emphasized.},
	Author = {Renner, S. and Popov, M. and Schuffenhauer, A. and Roth, H. J. and Breitenstein, W. and Marzinzik, A. and Lewis, I. and Krastel, P. and Nigsch, F. and Jenkins, J. and Jacoby, E.},
	Date-Added = {2015-11-11 13:31:34 +0000},
	Date-Modified = {2015-11-11 13:31:34 +0000},
	Doi = {10.4155/fmc.11.15},
	Journal = {Future Med Chem},
	Month = {Apr},
	Number = {6},
	Pages = {751--766},
	Title = {{{R}ecent trends and observations in the design of high-quality screening collections}},
	Volume = {3},
	Year = {2011},
	Bdsk-Url-1 = {http://dx.doi.org/10.4155/fmc.11.15}}

@article{Gubler2013IC50,
	Abstract = {The four-parameter logistic Hill equation models the theoretical relationship between inhibitor concentration and response and is used to derive IC(50) values as a measure of compound potency. This relationship is the basis for screening strategies that first measure percent inhibition at a single, uniform concentration and then determine IC(50) values for compounds above a threshold. In screening practice, however, a "good" correlation between percent inhibition values and IC(50) values is not always observed, and in the literature, there seems confusion about what correlation even to expect. We examined the relationship between percent inhibition data and IC(50) data in HDAC4 and ENPP2 high-throughput screening (HTS) data sets and compared our findings with a series of numerical simulations that allowed the investigation of the influence of parameters representing different types of uncertainties: variability in the screening concentration (related to solution library and compound characteristics, liquid handling), variations in Hill model parameters (related to interaction of compounds with target, type of assay), and influences of assay data quality parameters (related to assay and experimental design, liquid handling). In the different sensitivity analyses, we found that the typical variations of the actual compound concentrations in existing screening libraries generate the largest contributions to imperfect correlations. Excess variability in the ENPP2 assay above the values of the simulation model can be explained by compound aggregation artifacts.},
	Author = {Gubler, H. and Schopfer, U. and Jacoby, E.},
	Date-Added = {2015-11-11 13:31:34 +0000},
	Date-Modified = {2015-11-11 13:31:34 +0000},
	Doi = {10.1177/1087057112455219},
	Journal = {J Biomol Screen},
	Month = {Jan},
	Number = {1},
	Pages = {1--13},
	Title = {{{T}heoretical and {E}xperimental {R}elationships between {P}ercent {I}nhibition and {I}{C}50 {D}ata {O}bserved in {H}igh-{T}hroughput {S}creening}},
	Volume = {18},
	Year = {2013},
	Bdsk-Url-1 = {http://dx.doi.org/10.1177/1087057112455219}}

@article{Varin2012Latent,
	Abstract = {Recently a novel method termed compound set enrichment (CSE) has been described that uses the activity distribution of a structural class of compounds to identify hit series from primary screening data. This report describes how this method can be used to identify such hit series, even when no hits according to conventional hit-calling methods for a given structural class are present in the data set. Such series, which were called latent hit series, were identified prospectively in a cell-based screening campaign and also in a series of retrospective analyses of publicly available data sets from PubChem. The assay used for the prospective case study was developed to identify compounds modulating protein translation directed from the internal ribosome entry site (IRES) of the encephalomyocarditis virus (EMCV) genomic RNA. The assay was designed with the ability to detect two assay readouts. The first assay readout monitors compound effects on IRES-directed translation, and the second readout monitors the cell viability and general effect on protein expression. By applying CSE separately to both of them, six validated latent hit series with apparently no effects on cell viability were identified. For each of these series, further testing of new compounds enabled identification of additional hits, also apparently with no effect on cell viability. These validated latent hit series would have been missed by a conventional cutoff-based hit-calling approach. This prospective study further supports CSE as a method for the analysis of high-throughput screening experiments.},
	Author = {Varin, T. and Didiot, M. C. and Parker, C. N. and Schuffenhauer, A.},
	Date-Added = {2015-11-11 13:31:34 +0000},
	Date-Modified = {2016-01-05 17:14:15 +0000},
	Doi = {10.1021/jm201328e},
	Journal = {J.~Med.~Chem.},
	Month = {Feb},
	Number = {3},
	Pages = {1161--1170},
	Title = {{{L}atent hit series hidden in high-throughput screening data}},
	Volume = {55},
	Year = {2012},
	Bdsk-Url-1 = {http://dx.doi.org/10.1021/jm201328e}}

@article{Varin2011ScafNet,
	Abstract = {Identification of meaningful chemical patterns in the increasing amounts of high-throughput-generated bioactivity data available today is an increasingly important challenge for successful drug discovery. Herein, we present the scaffold network as a novel approach for mapping and navigation of chemical and biological space. A scaffold network represents the chemical space of a library of molecules consisting of all molecular scaffolds and smaller "parent" scaffolds generated therefrom by the pruning of rings, effectively leading to a network of common scaffold substructure relationships. This algorithm provides an extension of the scaffold tree algorithm that, instead of a network, generates a tree relationship between a heuristically rule-based selected subset of parent scaffolds. The approach was evaluated for the identification of statistically significantly active scaffolds from primary screening data for which the scaffold tree approach has already been shown to be successful. Because of the exhaustive enumeration of smaller scaffolds and the full enumeration of relationships between them, about twice as many statistically significantly active scaffolds were identified compared to the scaffold-tree-based approach. We suggest visualizing scaffold networks as islands of active scaffolds.},
	Author = {Varin, T. and Schuffenhauer, A. and Ertl, P. and Renner, S.},
	Date-Added = {2015-11-11 13:31:34 +0000},
	Date-Modified = {2015-11-11 13:31:34 +0000},
	Doi = {10.1021/ci2000924},
	Journal = {J Chem Inf Model},
	Month = {Jul},
	Number = {7},
	Pages = {1528--1538},
	Title = {{{M}ining for bioactive scaffolds with scaffold networks: improved compound set enrichment from primary screening data}},
	Volume = {51},
	Year = {2011},
	Bdsk-Url-1 = {http://dx.doi.org/10.1021/ci2000924}}

@article{Ertl2011ScaffoldTree,
	Abstract = {The Scaffold Tree algorithm (J Chem Inf Model 47:47-58, 2007) allows to organize large molecular data sets by arranging sets of molecules into a unique tree hierarchy based on their scaffolds, with scaffolds forming leaf nodes of such tree. The hierarchy is created by iterative removal of rings from more complex scaffolds using chemically meaningful set of rules, until a single, root ring is obtained. The classification is deterministic, data set independent, and scales linearly with the number of compounds included in the data set. In this review we summarize the basic principles of the Scaffold Tree methodology and review its applications, which appeared in recent medicinal chemistry literature, including the use of Scaffold Trees for visualization of large chemical data sets, compound clustering, and the identification of novel bioactive molecules. References to several computer programs, including also free tools available on the Internet, allowing to perform classification and visualization of molecules based on their scaffolds are also provided.},
	Author = {Ertl, P. and Schuffenhauer, A. and Renner, S.},
	Date-Added = {2015-11-11 13:31:34 +0000},
	Date-Modified = {2015-11-11 13:31:34 +0000},
	Journal = {Methods Mol. Biol.},
	Pages = {245--260},
	Title = {{{T}he scaffold tree: an efficient navigation in the scaffold universe}},
	Volume = {672},
	Year = {2011}}

@article{Varin2010CSE,
	Abstract = {The main goal of high-throughput screening (HTS) is to identify active chemical series rather than just individual active compounds. In light of this goal, a new method (called compound set enrichment) to identify active chemical series from primary screening data is proposed. The method employs the scaffold tree compound classification in conjunction with the Kolmogorov-Smirnov statistic to assess the overall activity of a compound scaffold. The application of this method to seven PubChem data sets (containing between 9389 and 263679 molecules) is presented, and the ability of this method to identify compound classes with only weakly active compounds (potentially latent hits) is demonstrated. The analysis presented here shows how methods based on an activity cutoff can distort activity information, leading to the incorrect activity assignment of compound series. These results suggest that this method might have utility in the rational selection of active classes of compounds (and not just individual active compounds) for followup and validation.},
	Author = {Varin, T. and Gubler, H. and Parker, C. N. and Zhang, J. H. and Raman, P. and Ertl, P. and Schuffenhauer, A.},
	Date-Added = {2015-11-11 13:31:34 +0000},
	Date-Modified = {2015-11-11 13:31:34 +0000},
	Doi = {10.1021/ci100203e},
	Journal = {J Chem Inf Model},
	Month = {Dec},
	Number = {12},
	Pages = {2067--2078},
	Title = {{{C}ompound set enrichment: a novel approach to analysis of primary {H}{T}{S} data}},
	Volume = {50},
	Year = {2010},
	Bdsk-Url-1 = {http://dx.doi.org/10.1021/ci100203e}}

@article{Renner2009Bioact,
	Abstract = {The structure- and chemistry-based hierarchical organization of library scaffolds in tree-like arrangements provides a valid, intuitive means to map and navigate chemical space. We demonstrate that scaffold trees built using bioactivity as the key selection criterion for structural simplification during tree construction allow efficient and intuitive mapping, visualization and navigation of the chemical space defined by a given library, which in turn allows correlation of this chemical space with the investigated bioactivity and further compound design. Brachiation along the branches of such trees from structurally complex to simple scaffolds with retained yet varying bioactivity is feasible at high frequency for the five major pharmaceutically relevant target classes and allows for the identification of new inhibitor types for a given target. We provide proof of principle by identifying new active scaffolds for 5-lipoxygenase and the estrogen receptor ERalpha.},
	Author = {Renner, S. and van Otterlo, W. A. and Dominguez Seoane, M. and Mocklinghoff, S. and Hofmann, B. and Wetzel, S. and Schuffenhauer, A. and Ertl, P. and Oprea, T. I. and Steinhilber, D. and Brunsveld, L. and Rauh, D. and Waldmann, H.},
	Date-Added = {2015-11-11 13:31:34 +0000},
	Date-Modified = {2015-11-11 13:31:34 +0000},
	Journal = {Nat. Chem. Biol.},
	Month = {Aug},
	Number = {8},
	Pages = {585--592},
	Title = {{{B}ioactivity-guided mapping and navigation of chemical space}},
	Volume = {5},
	Year = {2009}}

@article{Schuffenhauer2007ScaffoldTree,
	Abstract = {A hierarchical classification of chemical scaffolds (molecular framework, which is obtained by pruning all terminal side chains) has been introduced. The molecular frameworks form the leaf nodes in the hierarchy trees. By an iterative removal of rings, scaffolds forming the higher levels in the hierarchy tree are obtained. Prioritization rules ensure that less characteristic, peripheral rings are removed first. All scaffolds in the hierarchy tree are well-defined chemical entities making the classification chemically intuitive. The classification is deterministic, data-set-independent, and scales linearly with the number of compounds included in the data set. The application of the classification is demonstrated on two data sets extracted from the PubChem database, namely, pyruvate kinase binders and a collection of pesticides. The examples shown demonstrate that the classification procedure handles robustly synthetic structures and natural products.},
	Author = {Schuffenhauer, A. and Ertl, P. and Roggo, S. and Wetzel, S. and Koch, M. A. and Waldmann, H.},
	Date-Added = {2015-11-11 13:31:34 +0000},
	Date-Modified = {2015-11-11 13:31:34 +0000},
	Journal = {J Chem Inf Model},
	Number = {1},
	Pages = {47--58},
	Title = {{{T}he scaffold tree--visualization of the scaffold universe by hierarchical scaffold classification}},
	Volume = {47},
	Year = {2007}}

@article{Brown2006HitList,
	Abstract = {The high-throughput affinity-selection screening platform SpeedScreen was recently reported by the Novartis Institutes for BioMedical Research as a homogeneous, label-free screening technology with mass-spectrometry readout. SpeedScreen relies on the screening of compound mixtures with various target proteins and uses fast size-exclusion chromatography to separate target-bound from unbound substances. After disintegration of the target-binder complex, the binder molecules are identified by their molecular masses using liquid chromatography/mass spectrometry. The authors report an analysis of the molecular properties of hits obtained with SpeedScreen on 26 targets screened within the past few years at Novartis using this technology. Affinity-based SpeedScreen is a robust high-throughput screening technology that does not accumulate frequent hitters or potential covalent binders. The hits are representative of the most commonly identified scaffold classes observed for known drugs. Validated SpeedScreen hits tend to be enriched on more lipophilic and larger-molecular-weight compounds compared to the whole library. The potential for a reduced SpeedScreen screening set to be used in case only limited protein quantities are available is evaluated. Such a reduced compound set should also maximize the coverage of the high-performing regions of the chemical property and class spaces; chemoinformatics methods including genetic algorithms and divisive K-means clustering are used for this aim.},
	Author = {Brown, N. and Zehender, H. and Azzaoui, K. and Schuffenhauer, A. and Mayr, L. M. and Jacoby, E.},
	Date-Added = {2015-11-11 13:31:34 +0000},
	Date-Modified = {2015-11-11 13:31:34 +0000},
	Doi = {10.1177/1087057105283579},
	Journal = {J Biomol Screen},
	Month = {Mar},
	Number = {2},
	Pages = {123--130},
	Title = {{{A} chemoinformatics analysis of hit lists obtained from high-throughput affinity-selection screening}},
	Volume = {11},
	Year = {2006},
	Bdsk-Url-1 = {http://dx.doi.org/10.1177/1087057105283579}}

@article{Gunera2015,
	Abstract = {Fragment-based searching and abstract representation of molecular features through reduced graphs have separately been used for virtual screening. Here, we combine these two approaches and apply the algorithm RedFrag to virtual screens retrospectively and prospectively. It uses a new type of reduced graph that does not suffer from information loss during its construction and bypasses the necessity of feature definitions. Built upon chemical epitopes resulting from molecule fragmentation, the reduced graph embodies physico-chemical and 2D-structural properties of a molecule. Reduced graphs are compared with a continuous-similarity-distance-driven maximal common subgraph algorithm, which calculates similarity at the fragmental and topological levels. The performance of the algorithm is evaluated by retrieval experiments utilizing precompiled validation sets. By predicting and experimentally testing ligands for endothiapepsin, a challenging model protease, the method is assessed in a prospective setting. Here, we identified five novel ligands with affinities as low as 2.08 uM.},
	Author = {Gunera, J. and Kolb, P.},
	Date-Added = {2015-11-11 13:31:34 +0000},
	Date-Modified = {2015-11-11 13:31:34 +0000},
	Journal = {J Comput Chem},
	Month = {Aug},
	Number = {21},
	Pages = {1597--1608},
	Title = {{{F}ragment-based similarity searching with infinite color space}},
	Volume = {36},
	Year = {2015}}

@article{Barker2006ScafHopRG,
	Abstract = {Similarity-based methods for virtual screening are widely used. However, conventional searching using 2D chemical fingerprints or 2D graphs may retrieve only compounds which are structurally very similar to the original target molecule. Of particular current interest then is scaffold hopping, that is, the ability to identify molecules that belong to different chemical series but which could form the same interactions with a receptor. Reduced graphs provide summary representations of chemical structures and, therefore, offer the potential to retrieve compounds that are similar in terms of their gross features rather than at the atom-bond level. Using only a fingerprint representation of such graphs, we have previously shown that actives retrieved were more diverse than those found using Daylight fingerprints. Maximum common substructures give an intuitively reasonable view of the similarity between two molecules. However, their calculation using graph-matching techniques is too time-consuming for use in practical similarity searching in larger data sets. In this work, we exploit the low cardinality of the reduced graph in graph-based similarity searching. We reinterpret the reduced graph as a fully connected graph using the bond-distance information of the original graph. We describe searches, using both the maximum common induced subgraph and maximum common edge subgraph formulations, on the fully connected reduced graphs and compare the results with those obtained using both conventional chemical and reduced graph fingerprints. We show that graph matching using fully connected reduced graphs is an effective retrieval method and that the actives retrieved are likely to be topologically different from those retrieved using conventional 2D methods.},
	Author = {Barker, E. J. and Buttar, D. and Cosgrove, D. A. and Gardiner, E. J. and Kitts, P. and Willett, P. and Gillet, V. J.},
	Date-Added = {2015-11-11 13:31:34 +0000},
	Date-Modified = {2015-11-11 13:31:34 +0000},
	Journal = {J Chem Inf Model},
	Number = {2},
	Pages = {503--511},
	Title = {{{S}caffold hopping using clique detection applied to reduced graphs}},
	Volume = {46},
	Year = {2006}}

@article{Stiefl2006RG,
	Abstract = {An extended reduced graph approach (ErG) is presented that uses pharmacophore-type node descriptions to encode the relevant molecular properties. The basic idea of the method can be described as a hybrid approach of reduced graphs (Gillet et al. J. Chem. Inf. Comput. Sci. 2003, 43, 338-345) and binding property pairs (Kearsley et al. J. Chem. Inf. Comput. Sci. 1996, 36, 118-127). However, specific extension modifications to correctly describe the pharmacophoric properties, size, and shape of the molecules under study result in a very stable and good performance as compared to DAYLIGHT fingerprints (DFP). This is exemplified for 11 activity classes of the MDL Drug Data Report database, for which ErG performs as well or better than DFP in 10 cases. On the basis of the example data sets, the ability of ErG to switch from one chemotype to another (often referred to as "scaffold hopping") is highlighted. Additionally, possible pitfalls of reduced graph approaches as well as suitable solutions are discussed with the help of example structures. Overall, it is shown that ErG is a widely applicable method capable of identifying structurally diverse actives for a given active search query. This diversity is achieved by a high degree of molecular abstraction, which in turn results in a low dimensional descriptor vector that allows very low computation times for similarity searches.},
	Author = {Stiefl, N. and Watson, I. A. and Baumann, K. and Zaliani, A.},
	Date-Added = {2015-11-11 13:31:34 +0000},
	Date-Modified = {2015-11-11 13:31:34 +0000},
	Journal = {J Chem Inf Model},
	Number = {1},
	Pages = {208--220},
	Title = {{{E}r{G}: 2{D} pharmacophore descriptions for scaffold hopping}},
	Volume = {46},
	Year = {2006}}

@article{Birchall2008MOGA,
	Abstract = {A multiobjective evolutionary algorithm (MOEA) is described for evolving multiple structure-activity relationships (SARs). The SARs are encoded in easy-to-interpret reduced graph queries which describe features that are preferentially present in active compounds compared to inactives. The MOEA addresses a limitation associated with many machine learning methods; that is, the inherent tradeoff that exists in recall and precision which is usually handled by combining the two objectives into a single measure with a consequent loss of control. By simultaneously optimizing recall and precision, the MOEA generates a family of SARs that lie on the precision-recall (PR) curve. The user is then able to select a query with an appropriate balance in the two objectives: for example, a low recall-high precision query may be preferred when establishing the SAR, whereas a high recall-low precision query may be more appropriate in a virtual screening context. Each query on the PR curve aims at capturing the structure-activity information into a single representation, and each can be considered as an alternative (equally valid) solution. We then investigate combining individual queries into teams with the aim of capturing multiple SARs that may exist in a data set, for example, as is commonly seen in high-throughput screening data sets. Team formation is carried out iteratively as a postprocessing step following the evolution of the individual queries. The inclusion of uniqueness as a third objective within the MOEA provides an effective way of ensuring the queries are complementary in the active compounds they describe. Substantial improvements in both recall and precision are seen for some data sets. Furthermore, the resulting queries provide more detailed structure-activity information than is present in a single query.},
	Author = {Birchall, K. and Gillet, V. J. and Harper, G. and Pickett, S. D.},
	Date-Added = {2015-11-11 13:31:34 +0000},
	Date-Modified = {2015-11-11 13:31:34 +0000},
	Journal = {J Chem Inf Model},
	Month = {Aug},
	Number = {8},
	Pages = {1558--1570},
	Title = {{{E}volving interpretable structure-activity relationship models. 2. {U}sing multiobjective optimization to derive multiple models}},
	Volume = {48},
	Year = {2008}}

@article{Birchall2008RGquery,
	Abstract = {A new machine learning method is presented for extracting interpretable structure-activity relationships from screening data. The method is based on an evolutionary algorithm and reduced graphs and aims to evolve a reduced graph query (subgraph) that is present within the active compounds and absent from the inactives. The reduced graph representation enables heterogeneous compounds, such as those found in high-throughput screening data, to be captured in a single representation with the resulting query encoding structure-activity information in a form that is readily interpretable by a chemist. The application of the method is illustrated using data sets extracted from the well-known MDDR data set and GSK in-house screening data. Queries are evolved that are consistent with the known SARs, and they are also shown to be robust when applied to independent sets that were not used in training.},
	Author = {Birchall, K. and Gillet, V. J. and Harper, G. and Pickett, S. D.},
	Date-Added = {2015-11-11 13:31:34 +0000},
	Date-Modified = {2015-11-11 13:31:34 +0000},
	Journal = {J Chem Inf Model},
	Month = {Aug},
	Number = {8},
	Pages = {1543--1557},
	Title = {{{E}volving interpretable structure-activity relationships. 1. {R}educed graph queries}},
	Volume = {48},
	Year = {2008}}

@article{Barker2003RG,
	Abstract = {Reduced graphs provide summary representations of chemical structures. Here, a variety of different types of reduced graphs are compared in similarity searches. The reduced graphs are found to give comparable performance to Daylight fingerprints in terms of the number of active compounds retrieved. However, no one type of reduced graph is found to be consistently superior across a variety of different data sets. Consequently, a representative set of reduced graphs was chosen and used together with Daylight fingerprints in data fusion experiments. The results show improved performance in 10 out of 11 data sets compared to using Daylight fingerprints alone. Finally, the potential of using reduced graphs to build SAR models is demonstrated using recursive partitioning. An SAR model consistent with a published model is found following just two splits in the decision tree.},
	Author = {Barker, E. J. and Gardiner, E. J. and Gillet, V. J. and Kitts, P. and Morris, J.},
	Date-Added = {2015-11-11 13:31:34 +0000},
	Date-Modified = {2015-11-11 13:31:34 +0000},
	Journal = {J Chem Inf Comput Sci},
	Number = {2},
	Pages = {346--356},
	Title = {{{F}urther development of reduced graphs for identifying bioactive compounds}},
	Volume = {43},
	Year = {2003}}

@article{Yongye2013ScafSelProm,
	Abstract = {The concept of a recurrent scaffold present in a series of structures is common in medicinal drug discovery. We present a scaffold analysis of compounds screened across 100 sequence-unrelated proteins to identify scaffolds that drive promiscuity or selectivity. Selectivity and promiscuity play a major role in traditional and poly-pharmacological drug design considerations. The collection employed here is the first publicly available data set containing the complete screening profiles of more than 15 000 compounds from different sources. In addition, no scaffold analysis of this data set has been reported. The protocol described here employs the Molecular Equivalence Index tool to facilitate the selection of Bemis-Murcko frameworks in the data set, which contain at least five compounds and Scaffold Hunter to generate a hierarchical tree of scaffolds. The annotation of the scaffold tree with protein-binding profile data enabled the successful identification of mostly highly specific compounds, due to data set constraints. We also applied this approach to a public set of 1497 small molecules screened non-uniformly across a panel of 172 protein kinases. The approach is general and can be applied to any other data sets and activity readout.},
	Author = {Yongye, A. B. and Medina-Franco, J. L.},
	Date-Added = {2015-11-11 13:31:34 +0000},
	Date-Modified = {2016-01-05 17:14:05 +0000},
	Journal = {Chem.~Biol.~Drug Des.},
	Month = {Oct},
	Number = {4},
	Pages = {367--375},
	Title = {{{T}oward an efficient approach to identify molecular scaffolds possessing selective or promiscuous compounds}},
	Volume = {82},
	Year = {2013}}

@article{Aronov2008KinFrag,
	Abstract = {Small molecule protein kinase inhibitors are widely employed as biological reagents and as leads in the design of drugs for a variety of diseases. We investigated the phenomenon of kinase-likeness, i.e., the propensity of ligands to inhibit protein kinases, in the context of kinase-specific substructural fragments. The frequency of occurrence of multiple structural fragments in kinase inhibitor libraries relative to nonkinase compounds has been analyzed. A combination of structural fragment counts, termed the "2-0" kinase-likeness rule, provides approximately 5-fold enrichment in kinase active compounds. This rule has been validated using in-house kinase counterscreening data and applied prospectively to uncover kinase activities in marketed drugs. In addition, the role of discriminating fragments in kinase recognition was interrogated using available structural data, providing an insight into their effect on inhibitor potency and selectivity. One of these fragments, bisarylaniline, has been characterized as a kinase-privileged fragment with specific binding preferences and a link to increased activity within kinases.},
	Author = {Aronov, A. M. and McClain, B. and Moody, C. S. and Murcko, M. A.},
	Date-Added = {2015-11-11 13:31:34 +0000},
	Date-Modified = {2015-11-11 13:31:34 +0000},
	Journal = {J. Med. Chem.},
	Month = {Mar},
	Number = {5},
	Pages = {1214--1222},
	Title = {{{K}inase-likeness and kinase-privileged fragments: toward virtual polypharmacology}},
	Volume = {51},
	Year = {2008}}

@article{BemisMurcko1999,
	Abstract = {We continue our study of the common features present in drug molecules by looking in detail at drug side chains. Using shape description methods, we divide a database of commercially available drugs into a list of common drug side chains. On the basis of the atom pair shape descriptor (taking into account atom type, hybridization, and bond order), there are 1,246 different side chains among the 5,090 compounds analyzed. The average number of side chains per molecule is 4, and the average number of heavy atoms per side chain is 2. If we ignore the carbonyl side chain, then there are approximately 15,000 occurrences of side chains. Of these 15,000 approximately 11,000 are from the "top 20" group of side chains. This suggests that the diversity that side chains provide to drug molecules is quite low. We discuss ways that this work could be used to provide guidance for molecular design efforts.},
	Author = {Bemis, G. W. and Murcko, M. A.},
	Date-Added = {2015-11-11 13:31:34 +0000},
	Date-Modified = {2015-11-11 13:31:34 +0000},
	Journal = {J. Med. Chem.},
	Month = {Dec},
	Number = {25},
	Pages = {5095--5099},
	Title = {{{P}roperties of known drugs. 2. {S}ide chains}},
	Volume = {42},
	Year = {1999}}

@article{BemisMurcko1996,
	Abstract = {In order to better understand the common features present in drug molecules, we use shape description methods to analyze a database of commercially available drugs and prepare a list of common drug shapes. A useful way of organizing this structural data is to group the atoms of each drug molecule into ring, linker, framework, and side chain atoms. On the basis of the two-dimensional molecular structures (without regard to atom type, hybridization, and bond order), there are 1179 different frameworks among the 5120 compounds analyzed. However, the shapes of half of the drugs in the database are described by the 32 most frequently occurring frameworks. This suggests that the diversity of shapes in the set of known drugs is extremely low. In our second method of analysis, in which atom type, hybridization, and bond order are considered, more diversity is seen; there are 2506 different frameworks among the 5120 compounds in the database, and the most frequently occurring 42 frameworks account for only one-fourth of the drugs. We discuss the possible interpretations of these findings and the way they may be used to guide future drug discovery research.},
	Author = {Bemis, G. W. and Murcko, M. A.},
	Date-Added = {2015-11-11 13:31:34 +0000},
	Date-Modified = {2015-11-11 13:31:34 +0000},
	Journal = {J. Med. Chem.},
	Month = {Jul},
	Number = {15},
	Pages = {2887--2893},
	Title = {{{T}he properties of known drugs. 1. {M}olecular frameworks}},
	Volume = {39},
	Year = {1996}}

@article{Schneider1999ScafHopTP,
	Abstract = {A chemically advanced template search (CATS) based on topological pharmacophore models has been developed as a technique for virtual screening. This technique has successfully identified novel potent Ca(2+) antagonists (such as 2) that have a similar activity to 1 (a known T-channel blocking agent) in a library of several hundred thousand compounds on the basis of a correlation vector representation.},
	Author = {Schneider, G. and Neidhart, W. and Giller, T. and Schmid, G.},
	Date-Added = {2015-11-11 13:31:34 +0000},
	Date-Modified = {2015-11-11 13:31:34 +0000},
	Journal = {Angew. Chem. Int. Ed. Engl.},
	Month = {Oct},
	Number = {19},
	Pages = {2894--2896},
	Title = {{"{S}caffold-{H}opping" by {T}opological {P}harmacophore {S}earch: {A} {C}ontribution to {V}irtual {S}creening}},
	Volume = {38},
	Year = {1999}}

@article{Hubel1980TopPh4,
	Abstract = {A simple approach to evaluate logical pharmacophores on the base of topological features is described. It is based on considerations of the relative frequencies of structural features within different classes of activity. Shannon's entropy is used in the case of more than two classes. To obtain a pharmacophore a stepwise interactive procedure is performed. The algorithm is applied to fungicidal carboxamides and beta-adrenergic phenethylamine agonists and antagonists. In both cases meaningful pharmacophores could be obtained.},
	Author = {Hubel, S. and Rosner, T. and Franke, R.},
	Date-Added = {2015-11-11 13:31:34 +0000},
	Date-Modified = {2015-11-11 13:31:34 +0000},
	Journal = {Pharmazie},
	Number = {7},
	Pages = {424--433},
	Title = {{{T}he evaluation of topological pharmacophores by heuristic approach}},
	Volume = {35},
	Year = {1980}}

@article{Harper2004DDclus,
	Abstract = {Virtual screening and high-throughput screening are two major components of lead discovery within the pharmaceutical industry. In this paper we describe improvements to previously published methods for similarity searching with reduced graphs, with a particular focus on ligand-based virtual screening, and describe a novel use of reduced graphs in the clustering of high-throughput screening data. Literature methods for reduced graph similarity searching encode the reduced graphs as binary fingerprints, which has a number of issues. In this paper we extend the definition of the reduced graph to include positively and negatively ionizable groups and introduce a new method for measuring the similarity of reduced graphs based on a weighted edit distance. Moving beyond simple similarity searching, we show how more flexible queries can be built using reduced graphs and describe a database system that allows iterative querying with multiple representations. Reduced graphs capture many important features of ligand-receptor interactions and, in conjunction with other whole molecule descriptors, provide an informative way to review HTS data. We describe a novel use of reduced graphs in this context, introducing a method we have termed data-driven clustering, that identifies clusters of molecules represented by a particular whole molecule descriptor and enriched in active compounds.},
	Author = {Harper, G. and Bravi, G. S. and Pickett, S. D. and Hussain, J. and Green, D. V.},
	Date-Added = {2015-11-11 13:31:34 +0000},
	Date-Modified = {2015-11-11 13:31:34 +0000},
	Journal = {J Chem Inf Comput Sci},
	Number = {6},
	Pages = {2145--2156},
	Title = {{{T}he reduced graph descriptor in virtual screening and data-driven clustering of high-throughput screening data}},
	Volume = {44},
	Year = {2004}}

@article{Koch1997MCSprot,
	Author = {Koch, I. and Lengauer, T.},
	Date-Added = {2015-11-11 13:31:34 +0000},
	Date-Modified = {2015-11-11 13:31:34 +0000},
	Journal = {Proc Int Conf Intell Syst Mol Biol},
	Pages = {167--178},
	Title = {{{D}etection of distant structural similarities in a set of proteins using a fast graph-based method}},
	Volume = {5},
	Year = {1997}}

@article{Quintus2009MCS,
	Author = {Quintus, F. and Sperandio, O. and Grynberg, J. and Petitjean, M. and Tuffery, P.},
	Date-Added = {2015-11-11 13:31:34 +0000},
	Date-Modified = {2015-11-11 13:59:27 +0000},
	Journal = {{BMC} Bioinformatics},
	Pages = {245},
	Title = {{{L}igand scaffold hopping combining 3{D} maximal substructure search and molecular similarity}},
	Volume = {10},
	Year = {2009}}







@article{Barone2001,
author = {Barone, RenÃ© and Chanon, Michel},
title = {A New and Simple Approach to Chemical Complexity. Application to the Synthesis of Natural Products},
journal = {J.~Chem.~Inf.~Comput.~Sci.},
volume = {41},
number = {2},
pages = {269-272},
year = {2001},
doi = {10.1021/ci000145p}}


